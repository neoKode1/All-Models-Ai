fal-ai/imagen4/preview

Imagen 4
Google’s highest quality image generation model
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Generate images using Google's Imagen 4 model.

Imagen 4 is designed to generate high-quality images with enhanced detail, richer lighting, and fewer artifacts. The model excels at:

Capturing fine details and textures
Rendering diverse art styles from photorealism to animation
Understanding natural language prompts
Maintaining high visual quality and composition
1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/imagen4/preview", {
  input: {
    prompt: "Capture an intimate close-up bathed in warm, soft, late-afternoon sunlight filtering into a quintessential 1960s kitchen. The focal point is a charmingly designed vintage package of all-purpose flour, resting invitingly on a speckled Formica countertop. The packaging itself evokes pure nostalgia: perhaps thick, slightly textured paper in a warm cream tone, adorned with simple, bold typography (a friendly serif or script) in classic red and blue “ALL-PURPOSE FLOUR”, featuring a delightful illustration like a stylized sheaf of wheat or a cheerful baker character. In smaller bold print at the bottom of the package: “NET WT 5 LBS (80 OZ) 2.27kg”. Focus sharply on the package details – the slightly soft edges of the paper bag, the texture of the vintage printing, the inviting \"All-Purpose Flour\" text. Subtle hints of the 1960s kitchen frame the shot – the chrome edge of the counter gleaming softly, a blurred glimpse of a pastel yellow ceramic tile backsplash, or the corner of a vintage metal canister set just out of focus. The shallow depth of field keeps attention locked on the beautifully designed package, creating an aesthetic rich in warmth, authenticity, and nostalgic appeal."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/imagen4/preview", {
  input: {
    prompt: "Capture an intimate close-up bathed in warm, soft, late-afternoon sunlight filtering into a quintessential 1960s kitchen. The focal point is a charmingly designed vintage package of all-purpose flour, resting invitingly on a speckled Formica countertop. The packaging itself evokes pure nostalgia: perhaps thick, slightly textured paper in a warm cream tone, adorned with simple, bold typography (a friendly serif or script) in classic red and blue “ALL-PURPOSE FLOUR”, featuring a delightful illustration like a stylized sheaf of wheat or a cheerful baker character. In smaller bold print at the bottom of the package: “NET WT 5 LBS (80 OZ) 2.27kg”. Focus sharply on the package details – the slightly soft edges of the paper bag, the texture of the vintage printing, the inviting \"All-Purpose Flour\" text. Subtle hints of the 1960s kitchen frame the shot – the chrome edge of the counter gleaming softly, a blurred glimpse of a pastel yellow ceramic tile backsplash, or the corner of a vintage metal canister set just out of focus. The shallow depth of field keeps attention locked on the beautifully designed package, creating an aesthetic rich in warmth, authenticity, and nostalgic appeal."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/imagen4/preview", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/imagen4/preview", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The text prompt describing what you want to see

negative_prompt string
A description of what to discourage in the generated images Default value: ""

aspect_ratio AspectRatioEnum
The aspect ratio of the generated image Default value: "1:1"

Possible enum values: 1:1, 16:9, 9:16, 3:4, 4:3

num_images integer
Number of images to generate (1-4) Default value: 1

seed integer
Random seed for reproducible generation

resolution ResolutionEnum
Default value: "1K"

Possible enum values: 1K, 2K


{
  "prompt": "Capture an intimate close-up bathed in warm, soft, late-afternoon sunlight filtering into a quintessential 1960s kitchen. The focal point is a charmingly designed vintage package of all-purpose flour, resting invitingly on a speckled Formica countertop. The packaging itself evokes pure nostalgia: perhaps thick, slightly textured paper in a warm cream tone, adorned with simple, bold typography (a friendly serif or script) in classic red and blue “ALL-PURPOSE FLOUR”, featuring a delightful illustration like a stylized sheaf of wheat or a cheerful baker character. In smaller bold print at the bottom of the package: “NET WT 5 LBS (80 OZ) 2.27kg”. Focus sharply on the package details – the slightly soft edges of the paper bag, the texture of the vintage printing, the inviting \"All-Purpose Flour\" text. Subtle hints of the 1960s kitchen frame the shot – the chrome edge of the counter gleaming softly, a blurred glimpse of a pastel yellow ceramic tile backsplash, or the corner of a vintage metal canister set just out of focus. The shallow depth of field keeps attention locked on the beautifully designed package, creating an aesthetic rich in warmth, authenticity, and nostalgic appeal.",
  "aspect_ratio": "1:1",
  "num_images": 1,
  "resolution": "1K"
}
Output
#
images list<File>
seed integer
Seed used for generation


{
  "images": [
    {
      "url": "https://v3.fal.media/files/rabbit/rmgBxhwGYb2d3pl3x9sKf_output.png"
    }
  ],
  "seed": 42
}
Other types
#
File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

fal-ai/flux-pro/kontext/max/text-to-image

Kontext [max] -- Text to Image
FLUX.1 Kontext [max] text-to-image is a new premium model brings maximum performance across all aspects – greatly improved prompt adherence.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
FLUX.1 Kontext [Max] -- Frontier image generation model.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/flux-pro/kontext/max/text-to-image", {
  input: {
    prompt: "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/flux-pro/kontext/max/text-to-image", {
  input: {
    prompt: "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/flux-pro/kontext/max/text-to-image", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/flux-pro/kontext/max/text-to-image", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The prompt to generate an image from.

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated image. Default value: "1:1"

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21


{
  "prompt": "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture.",
  "guidance_scale": 3.5,
  "num_images": 1,
  "output_format": "jpeg",
  "safety_tolerance": "2",
  "aspect_ratio": "1:1"
}
Output
#
images list<registry__image__fast_sdxl__models__Image>
The generated image files info.

timings Timings
seed integer
Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.

has_nsfw_concepts list<boolean>
Whether the generated images contain NSFW concepts.

prompt string
The prompt used for generating the image.


{
  "images": [
    {
      "url": "",
      "content_type": "image/jpeg"
    }
  ],
  "prompt": ""
}
Other types
#
registry__image__fast_sdxl__models__Image
#
url string
width integer
height integer
content_type string
Default value: "image/jpeg"

FluxProRedux
#
prompt string
The prompt to generate an image from. Default value: ""

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

FluxProV1Redux
#
prompt string
The prompt to generate an image from. Default value: ""

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

fal__toolkit__image__image__Image
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

width integer
The width of the image in pixels.

height integer
The height of the image in pixels.

FluxProUltraTextToImageInputRedux
#
prompt string
The prompt to generate an image from. Default value: ""

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

image_prompt_strength float
The strength of the image prompt, between 0 and 1. Default value: 0.1

aspect_ratio Enum | string
The aspect ratio of the generated image. Default value: 16:9

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21

raw boolean
Generate less processed, more natural-looking images.

ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512

fal-ai/flux-krea-lora/stream

Super fast endpoint for the FLUX.1 [dev] model with LoRA support, enabling rapid and high-quality image generation using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.
Inference
Commercial use
Streaming
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
FLUX.1 [dev], next generation text-to-image model.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/flux-krea-lora/stream", {
  input: {
    prompt: "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/flux-krea-lora/stream", {
  input: {
    prompt: "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/flux-krea-lora/stream", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/flux-krea-lora/stream", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The prompt to generate an image from.

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

loras list<LoraWeight>
The LoRAs to use for the image generation. You can use any number of LoRAs and they will be merged together to generate the final image.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.

num_images integer
The number of images to generate. This is always set to 1 for streaming output. Default value: 1

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png


{
  "prompt": "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture.",
  "image_size": "landscape_4_3",
  "num_inference_steps": 28,
  "guidance_scale": 3.5,
  "num_images": 1,
  "enable_safety_checker": true,
  "output_format": "jpeg"
}
Output
#
images list<Image>
The generated image files info.

timings Timings
seed integer
Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.

has_nsfw_concepts list<boolean>
Whether the generated images contain NSFW concepts.

prompt string
The prompt used for generating the image.


{
  "images": [
    {
      "url": "",
      "content_type": "image/jpeg"
    }
  ],
  "prompt": ""
}
Other types
#
ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512

LoraWeight
#
path string
URL or the path to the LoRA weights.

scale float
The scale of the LoRA weight. This is used to scale the LoRA weight before merging it with the base model. Default value: 1

Image
#
url string
width integer
height integer
content_type string
Default value: "image/jpeg"

fal-ai/recraft/v3/text-to-image

Text to Image
Recraft V3 is a text-to-image model with the ability to generate long texts, vector art, images in brand style, and much more. As of today, it is SOTA in image generation, proven by Hugging Face's industry-leading Text-to-Image Benchmark by Artificial Analysis.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Recraft V3

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/recraft/v3/text-to-image", {
  input: {
    prompt: "a red panda eating a bamboo in front of a poster that says \"recraft V3 now available at fal\""
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/recraft/v3/text-to-image", {
  input: {
    prompt: "a red panda eating a bamboo in front of a poster that says \"recraft V3 now available at fal\""
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/recraft/v3/text-to-image", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/recraft/v3/text-to-image", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
image_size ImageSize | Enum
Default value: square_hd

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
style StyleEnum
The style of the generated images. Vector images cost 2X as much. Default value: "realistic_image"

Possible enum values: any, realistic_image, digital_illustration, vector_illustration, realistic_image/b_and_w, realistic_image/hard_flash, realistic_image/hdr, realistic_image/natural_light, realistic_image/studio_portrait, realistic_image/enterprise, realistic_image/motion_blur, realistic_image/evening_light, realistic_image/faded_nostalgia, realistic_image/forest_life, realistic_image/mystic_naturalism, realistic_image/natural_tones, realistic_image/organic_calm, realistic_image/real_life_glow, realistic_image/retro_realism, realistic_image/retro_snapshot, realistic_image/urban_drama, realistic_image/village_realism, realistic_image/warm_folk, digital_illustration/pixel_art, digital_illustration/hand_drawn, digital_illustration/grain, digital_illustration/infantile_sketch, digital_illustration/2d_art_poster, digital_illustration/handmade_3d, digital_illustration/hand_drawn_outline, digital_illustration/engraving_color, digital_illustration/2d_art_poster_2, digital_illustration/antiquarian, digital_illustration/bold_fantasy, digital_illustration/child_book, digital_illustration/child_books, digital_illustration/cover, digital_illustration/crosshatch, digital_illustration/digital_engraving, digital_illustration/expressionism, digital_illustration/freehand_details, digital_illustration/grain_20, digital_illustration/graphic_intensity, digital_illustration/hard_comics, digital_illustration/long_shadow, digital_illustration/modern_folk, digital_illustration/multicolor, digital_illustration/neon_calm, digital_illustration/noir, digital_illustration/nostalgic_pastel, digital_illustration/outline_details, digital_illustration/pastel_gradient, digital_illustration/pastel_sketch, digital_illustration/pop_art, digital_illustration/pop_renaissance, digital_illustration/street_art, digital_illustration/tablet_sketch, digital_illustration/urban_glow, digital_illustration/urban_sketching, digital_illustration/vanilla_dreams, digital_illustration/young_adult_book, digital_illustration/young_adult_book_2, vector_illustration/bold_stroke, vector_illustration/chemistry, vector_illustration/colored_stencil, vector_illustration/contour_pop_art, vector_illustration/cosmics, vector_illustration/cutout, vector_illustration/depressive, vector_illustration/editorial, vector_illustration/emotional_flat, vector_illustration/infographical, vector_illustration/marker_outline, vector_illustration/mosaic, vector_illustration/naivector, vector_illustration/roundish_flat, vector_illustration/segmented_colors, vector_illustration/sharp_contrast, vector_illustration/thin, vector_illustration/vector_photo, vector_illustration/vivid_shapes, vector_illustration/engraving, vector_illustration/line_art, vector_illustration/line_circuit, vector_illustration/linocut

colors list<RGBColor>
An array of preferable colors

style_id string
The ID of the custom style reference (optional)

enable_safety_checker boolean
If set to true, the safety checker will be enabled.


{
  "prompt": "a red panda eating a bamboo in front of a poster that says \"recraft V3 now available at fal\"",
  "image_size": "square_hd",
  "style": "realistic_image",
  "colors": []
}
Output
#
images list<File>

{
  "images": [
    {
      "url": "https://fal.media/files/penguin/852yy3l5DGLmrwAK42RTB_image.webp"
    }
  ]
}
Other types
#
RGBColor
#
r integer
Red color value

g integer
Green color value

b integer
Blue color value

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512

fal-ai/hidream-i1-full

Text to Image
HiDream-I1 full is a new open-source image generative foundation model with 17B parameters that achieves state-of-the-art image generation quality within seconds.
Inference
Commercial use
Streaming
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Generate

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/hidream-i1-full", {
  input: {
    prompt: "a cat holding a skateboard which has 'fal' written on it in red spray paint"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
Streaming
#
This model supports streaming requests. You can stream data directly to the model and get the result in real-time.


import { fal } from "@fal-ai/client";

const stream = await fal.stream("fal-ai/hidream-i1-full", {
  input: {
    prompt: "a cat holding a skateboard which has 'fal' written on it in red spray paint"
  }
});

for await (const event of stream) {
  console.log(event);
}

const result = await stream.done();
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/hidream-i1-full", {
  input: {
    prompt: "a cat holding a skateboard which has 'fal' written on it in red spray paint"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/hidream-i1-full", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/hidream-i1-full", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The prompt to generate an image from.

negative_prompt string
The negative prompt to use. Use it to address details that you don't want in the image. This could be colors, objects, scenery and even the small details (e.g. moustache, blurry, low resolution). Default value: ""

image_size ImageSize | Enum
The size of the generated image.

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 50

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 5

sync_mode boolean
If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.

num_images integer
The number of images to generate. Default value: 1

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

loras list<LoraWeight>
A list of LoRAs to apply to the model. Each LoRA specifies its path, scale, and optional weight name.


{
  "prompt": "a cat holding a skateboard which has 'fal' written on it in red spray paint",
  "negative_prompt": "",
  "image_size": {
    "height": 1024,
    "width": 1024
  },
  "num_inference_steps": 50,
  "guidance_scale": 5,
  "num_images": 1,
  "enable_safety_checker": true,
  "output_format": "jpeg",
  "loras": []
}
Output
#

Other types
#
ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512

LoraWeight
#
path string
URL or the path to the LoRA weights.

weight_name string
Name of the LoRA weight. Used only if path is a Hugging Face repository, and required only if you have more than 1 safetensors file in the repo.

scale float
The scale of the LoRA weight. This is used to scale the LoRA weight before merging it with the base model. Default value: 1

Image
#
url string
width integer
height integer
content_type string
Default value: "image/jpeg"

creatify/lipsync

Realistic lipsync video - optimized for speed, quality, and consistency.
Inference
Commercial use
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Run

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("creatify/lipsync", {
  input: {
    audio_url: "https://v3.fal.media/files/penguin/IjB1sco-ydVA-szm3a1Rm_E_voice.mp3",
    video_url: "https://v3.fal.media/files/monkey/GzfGN-LfnbobjM9h2g5PF_Eduardo.mov"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("creatify/lipsync", {
  input: {
    audio_url: "https://v3.fal.media/files/penguin/IjB1sco-ydVA-szm3a1Rm_E_voice.mp3",
    video_url: "https://v3.fal.media/files/monkey/GzfGN-LfnbobjM9h2g5PF_Eduardo.mov"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("creatify/lipsync", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("creatify/lipsync", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
audio_url string
The audio url to use for lipsync

video_url string
The video url to use for lipsync

loop boolean
Default value: true


{
  "audio_url": "https://v3.fal.media/files/penguin/IjB1sco-ydVA-szm3a1Rm_E_voice.mp3",
  "video_url": "https://v3.fal.media/files/monkey/GzfGN-LfnbobjM9h2g5PF_Eduardo.mov",
  "loop": true
}
Output
#
video Video
The output of the lipsync


{
  "video": {
    "url": "https://v3.fal.media/files/koala/5whrKcxcHTTXzGNcep_MV_output.mp4"
  }
}
Other types
#
Video
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

fal-ai/kandinsky5/text-to-video

Text to Video
Kandinsky 5.0 is a diffusion model for fast, high-quality text-to-video generation.
Inference
Commercial use
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Generate a video based on the provided request parameters.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/kandinsky5/text-to-video", {
  input: {
    prompt: "A dog in red hat"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/kandinsky5/text-to-video", {
  input: {
    prompt: "A dog in red hat"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/kandinsky5/text-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/kandinsky5/text-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The text prompt to guide video generation.

resolution ResolutionEnum
Resolution of the generated video in W:H format. One of (768x512, 512x768, 512x512). Default value: "768x512"

Possible enum values: 768x512, 512x768, 512x512

video_length VideoLengthEnum
The length of the video to generate (5s or 10s) Default value: "5s"

Possible enum values: 5s, 10s

num_inference_steps integer
The number of inference steps. Default value: 30


{
  "prompt": "A dog in red hat",
  "resolution": "768x512",
  "video_length": "5s",
  "num_inference_steps": 30
}
Output
#
video File
The generated video file.


{
  "video": {
    "file_size": 5797172,
    "file_name": "output.mp4",
    "content_type": "application/octet-stream",
    "url": "https://v3b.fal.media/files/b/tiger/5d-CATfsfPrBaXAK38hy6_output.mp4"
  }
}
Other types
#
File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

KandinskyT2VDistillRequest
#
prompt string
The text prompt to guide video generation.

resolution ResolutionEnum
Resolution of the generated video in W:H format. One of (768x512, 512x768, 512x512). Default value: "768x512"

Possible enum values: 768x512, 512x768, 512x512

video_length VideoLengthEnum
The length of the video to generate (5s or 10s) Default value: "5s"

Possible enum values: 5s, 10s

fal-ai/pixverse/v5/image-to-video

Image to Video v5
Generate high quality video clips from text and image prompts using PixVerse v5
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Image To Video V5

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/pixverse/v5/image-to-video", {
  input: {
    prompt: "A woman warrior with her hammer walking with his glacier wolf.",
    image_url: "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/pixverse/v5/image-to-video", {
  input: {
    prompt: "A woman warrior with her hammer walking with his glacier wolf.",
    image_url: "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/pixverse/v5/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/pixverse/v5/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds Default value: "5"

Possible enum values: 5, 8

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

image_url string
URL of the image to use as the first frame


{
  "prompt": "A woman warrior with her hammer walking with his glacier wolf.",
  "aspect_ratio": "16:9",
  "resolution": "720p",
  "duration": "5",
  "negative_prompt": "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded",
  "image_url": "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
}
Output
#
video File
The generated video


{
  "video": {
    "file_size": 6420765,
    "file_name": "output.mp4",
    "content_type": "video/mp4",
    "url": "https://storage.googleapis.com/falserverless/model_tests/video_models/output-3.mp4"
  }
}
Other types
#
ExtendRequest
#
video_url string
URL of the input video to extend

prompt string
Prompt describing how to extend the video

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the extended video

Possible enum values: anime, 3d_animation, day, cyberpunk, comic

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video in seconds. 1080p videos are limited to 5 seconds Default value: "5"

Possible enum values: 5, 8

model ModelEnum
The model version to use for generation Default value: "v4.5"

Possible enum values: v3.5, v4, v4.5, v5

seed integer
Random seed for generation

I2VOutputV4
#
video File
The generated video

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

TransitionRequest
#
prompt string
The prompt for the transition

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 8

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

first_image_url string
URL of the image to use as the first frame

last_image_url string
URL of the image to use as the last frame

ImageToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds Default value: "5"

Possible enum values: 5, 8

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

image_url string
URL of the image to use as the first frame

FastImageToVideoRequestV4
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

image_url string
URL of the image to use as the first frame

camera_movement CameraMovementEnum
The type of camera movement to apply to the video

Possible enum values: horizontal_left, horizontal_right, vertical_up, vertical_down, zoom_in, zoom_out, crane_up, quickly_zoom_in, quickly_zoom_out, smooth_zoom_in, camera_rotation, robo_arm, super_dolly_out, whip_pan, hitchcock, left_follow, right_follow, pan_left, pan_right, fix_bg

VideoOutputV4
#
video File
The generated video

FastImageToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

image_url string
URL of the image to use as the first frame

FastExtendRequest
#
video_url string
URL of the input video to extend

prompt string
Prompt describing how to extend the video

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the extended video

Possible enum values: anime, 3d_animation, day, cyberpunk, comic

resolution ResolutionEnum
The resolution of the generated video. Fast mode doesn't support 1080p Default value: "720p"

Possible enum values: 360p, 540p, 720p

model ModelEnum
The model version to use for generation Default value: "v4.5"

Possible enum values: v3.5, v4, v4.5, v5

seed integer
Random seed for generation

TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds Default value: "5"

Possible enum values: 5, 8

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

TransitionOutputV5
#
video File
The generated video

FastTextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

VideoOutputV5
#
video File
The generated video

ImageToVideoRequestV4
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 4:3, 1:1, 3:4, 9:16

resolution ResolutionEnum
The resolution of the generated video Default value: "720p"

Possible enum values: 360p, 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds Default value: "5"

Possible enum values: 5, 8

negative_prompt string
Negative prompt to be used for the generation Default value: ""

style StyleEnum
The style of the generated video

Possible enum values: anime, 3d_animation, clay, comic, cyberpunk

seed integer
The same seed and the same prompt given to the same version of the model will output the same video every time.

image_url string
URL of the image to use as the first frame

camera_movement CameraMovementEnum
The type of camera movement to apply to the video

Possible enum values: horizontal_left, horizontal_right, vertical_up, vertical_down, zoom_in, zoom_out, crane_up, quickly_zoom_in, quickly_zoom_out, smooth_zoom_in, camera_rotation, robo_arm, super_dolly_out, whip_pan, hitchcock, left_follow, right_follow, pan_left, pan_right, fix_bg

SoundEffectRequest
#
video_url string
URL of the input video to add sound effects to

original_sound_switch boolean
Whether to keep the original audio from the video

prompt string
Description of the sound effect to generate. If empty, a random sound effect will be generated Default value: ""

LipsyncRequest
#
video_url string
URL of the input video

audio_url string
URL of the input audio. If not provided, TTS will be used.

voice_id VoiceIdEnum
Voice to use for TTS when audio_url is not provided Default value: "Auto"

Possible enum values: Emily, James, Isabella, Liam, Chloe, Adrian, Harper, Ava, Sophia, Julia, Mason, Jack, Oliver, Ethan, Auto

text string
Text content for TTS when audio_url is not provided

fal-ai/dreamomni2/edit

DreamOmni2 is a unified multimodal model for text and image guided image editing.
Inference
Commercial use
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Edit

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/dreamomni2/edit", {
  input: {
    image_urls: ["https://v3b.fal.media/files/b/koala/HB33rtG0ue7KzcIdQOTTX_dreamomni_ref_0.jpg", "https://v3b.fal.media/files/b/koala/BJMlXeNzOgGzyoO7XyGxr_dreamomni_ref_1.jpg"],
    prompt: "Replace the first image have the same image style as the second image."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/dreamomni2/edit", {
  input: {
    image_urls: ["https://v3b.fal.media/files/b/koala/HB33rtG0ue7KzcIdQOTTX_dreamomni_ref_0.jpg", "https://v3b.fal.media/files/b/koala/BJMlXeNzOgGzyoO7XyGxr_dreamomni_ref_1.jpg"],
    prompt: "Replace the first image have the same image style as the second image."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/dreamomni2/edit", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/dreamomni2/edit", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
image_urls list<string>
List of URLs of input images for editing.

prompt string
The prompt to edit the image.


{
  "image_urls": [
    "https://v3b.fal.media/files/b/koala/HB33rtG0ue7KzcIdQOTTX_dreamomni_ref_0.jpg",
    "https://v3b.fal.media/files/b/koala/BJMlXeNzOgGzyoO7XyGxr_dreamomni_ref_1.jpg"
  ],
  "prompt": "Replace the first image have the same image style as the second image."
}
Output
#
image Image
Generated image


{
  "image": {
    "file_size": 1473707,
    "file_name": "c9ab07096fdd47269a60bc556e01132b.png",
    "content_type": "image/png",
    "url": "https://v3b.fal.media/files/b/koala/prmop69b1g5lNFPE4RbCb_c9ab07096fdd47269a60bc556e01132b.png"
  }
}
Other types
#
Image
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

width integer
The width of the image in pixels.

height integer
The height of the image in pixels.

fal-ai/moondream3-preview/detect

Detect
Moondream 3 is a vision language model that brings frontier-level visual reasoning with native object detection, pointing, and OCR capabilities to real-world applications requiring fast, inexpensive inference at scale.
Inference
Commercial use
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Run Detect

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/moondream3-preview/detect", {
  input: {
    image_url: "https://storage.googleapis.com/falserverless/example_inputs/moondream-3-preview/detect_in.jpg",
    prompt: "Speed limit"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/moondream3-preview/detect", {
  input: {
    image_url: "https://storage.googleapis.com/falserverless/example_inputs/moondream-3-preview/detect_in.jpg",
    prompt: "Speed limit"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/moondream3-preview/detect", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/moondream3-preview/detect", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
image_url string
URL of the image to be processed

Max width: 7000px, Max height: 7000px, Timeout: 20.0s

prompt string
Object to be detected in the image

preview boolean
Whether to preview the output


{
  "image_url": "https://storage.googleapis.com/falserverless/example_inputs/moondream-3-preview/detect_in.jpg",
  "prompt": "Speed limit",
  "preview": true
}
Output
#
finish_reason string
Reason for finishing the output generation

usage_info UsageInfo
Usage information for the request

objects list<Object>
List of detected objects with their bounding boxes

image ImageFile
Image with bounding boxes drawn around detected objects


{
  "finish_reason": "stop",
  "usage_info": {
    "output_tokens": 23,
    "decode_time_ms": 811.5944429300725,
    "input_tokens": 737,
    "ttft_ms": 91.87838807702065,
    "prefill_time_ms": 54.45315001998097
  },
  "objects": [
    {
      "y_min": 0.16308235274382246,
      "x_max": 0.8755747037932524,
      "x_min": 0.8174849247502471,
      "y_max": 0.3061258583998726
    },
    {
      "y_min": 0.0987853935125991,
      "x_max": 0.7155113776357592,
      "x_min": 0.6706078794512399,
      "y_max": 0.21011001215700012
    }
  ],
  "image": "https://storage.googleapis.com/falserverless/example_outputs/moondream-3-preview/detect_out.png"
}
Other types
#
UsageInfo
#
input_tokens integer
Number of input tokens processed

output_tokens integer
Number of output tokens generated

prefill_time_ms float
Time taken for prefill in milliseconds

decode_time_ms float
Time taken for decoding in milliseconds

ttft_ms float
Time to first token in milliseconds

ImageFile
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

width integer
The width of the image

height integer
The height of the image

Point
#
x float
X coordinate of the point in normalized format (0 to 1)

y float
Y coordinate of the point in normalized format (0 to 1)

Object
#
x_min float
Left boundary of detection box in normalized format (0 to 1)

y_min float
Top boundary of detection box in normalized format (0 to 1)

x_max float
Right boundary of detection box in normalized format (0 to 1)

y_max float
Bottom boundary of detection box in normalized format (0 to 1)

fal-ai/sora-2/text-to-video/pro

Text to Video (Pro)
Text-to-video endpoint for Sora 2 Pro, OpenAI's state-of-the-art video model capable of creating richly detailed, dynamic clips with audio from natural language or images.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Generate a video from a text prompt using OpenAI's Sora 2 model.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/sora-2/text-to-video/pro", {
  input: {
    prompt: "A dramatic Hollywood breakup scene at dusk on a quiet suburban street. A man and a woman in their 30s face each other, speaking softly but emotionally, lips syncing to breakup dialogue. Cinematic lighting, warm sunset tones, shallow depth of field, gentle breeze moving autumn leaves, realistic natural sound, no background music"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/sora-2/text-to-video/pro", {
  input: {
    prompt: "A dramatic Hollywood breakup scene at dusk on a quiet suburban street. A man and a woman in their 30s face each other, speaking softly but emotionally, lips syncing to breakup dialogue. Cinematic lighting, warm sunset tones, shallow depth of field, gentle breeze moving autumn leaves, realistic natural sound, no background music"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/sora-2/text-to-video/pro", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/sora-2/text-to-video/pro", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
api_key string
The API key to use for the OpenAI API. If provided, you will not be billed for the request.

prompt string
The text prompt describing the video you want to generate

resolution ResolutionEnum
The resolution of the generated video Default value: "1080p"

Possible enum values: 720p, 1080p

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 9:16, 16:9

duration DurationEnum
Duration of the generated video in seconds Default value: "4"

Possible enum values: 4, 8, 12


{
  "prompt": "A dramatic Hollywood breakup scene at dusk on a quiet suburban street. A man and a woman in their 30s face each other, speaking softly but emotionally, lips syncing to breakup dialogue. Cinematic lighting, warm sunset tones, shallow depth of field, gentle breeze moving autumn leaves, realistic natural sound, no background music",
  "resolution": "1080p",
  "aspect_ratio": "16:9",
  "duration": 4
}
Output
#
video VideoFile
The generated video

video_id string
The ID of the generated video


{
  "video": {
    "content_type": "video/mp4",
    "url": "https://storage.googleapis.com/falserverless/example_outputs/sora-2-pro-t2v-output.mp4"
  },
  "video_id": "video_123"
}
Other types
#
VideoFile
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

width integer
The width of the video

height integer
The height of the video

fps float
The FPS of the video

duration float
The duration of the video

num_frames integer
The number of frames in the video

fal-ai/ovi

Text to video
A unified paradigm for audio-video generation
Inference
Commercial use
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Generate a video based on the provided request parameters.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/ovi", {
  input: {
    prompt: "A close-up of someone's face as they pet a cat, their hands stroking the soft fur in the foreground. Their affectionate expression shows as the cat purrs contentedly in their lap. They say, <S>This little guy has been with me for eight years now. He knows exactly when I need comfort. Animals are pretty amazing that way.<E>.<AUDCAP>Affectionate voice with cat purring and gentle petting sounds<ENDAUDCAP>"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/ovi", {
  input: {
    prompt: "A close-up of someone's face as they pet a cat, their hands stroking the soft fur in the foreground. Their affectionate expression shows as the cat purrs contentedly in their lap. They say, <S>This little guy has been with me for eight years now. He knows exactly when I need comfort. Animals are pretty amazing that way.<E>.<AUDCAP>Affectionate voice with cat purring and gentle petting sounds<ENDAUDCAP>"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/ovi", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/ovi", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The text prompt to guide video generation.

negative_prompt string
Negative prompt for video generation. Default value: "jitter, bad hands, blur, distortion"

num_inference_steps integer
The number of inference steps. Default value: 30

audio_negative_prompt string
Negative prompt for audio generation. Default value: "robotic, muffled, echo, distorted"

seed integer
Random seed for reproducibility. If None, a random seed is chosen.

resolution ResolutionEnum
Resolution of the generated video in W:H format. One of (512x992, 992x512, 960x512, 512x960, 720x720, or 448x1120). Default value: "992x512"

Possible enum values: 512x992, 992x512, 960x512, 512x960, 720x720, 448x1120, 1120x448


{
  "prompt": "A close-up of someone's face as they pet a cat, their hands stroking the soft fur in the foreground. Their affectionate expression shows as the cat purrs contentedly in their lap. They say, <S>This little guy has been with me for eight years now. He knows exactly when I need comfort. Animals are pretty amazing that way.<E>.<AUDCAP>Affectionate voice with cat purring and gentle petting sounds<ENDAUDCAP>",
  "negative_prompt": "jitter, bad hands, blur, distortion",
  "num_inference_steps": 30,
  "audio_negative_prompt": "robotic, muffled, echo, distorted",
  "resolution": "992x512"
}
Output
#
video File
The generated video file.

seed integer
The seed used for generation.


{
  "video": {
    "url": "https://storage.googleapis.com/falserverless/example_inputs/ovi_t2v_output.mp4"
  }
}
Other types
#
OviI2VRequest
#
prompt string
The text prompt to guide video generation.

negative_prompt string
Negative prompt for video generation. Default value: "jitter, bad hands, blur, distortion"

num_inference_steps integer
The number of inference steps. Default value: 30

audio_negative_prompt string
Negative prompt for audio generation. Default value: "robotic, muffled, echo, distorted"

seed integer
Random seed for reproducibility. If None, a random seed is chosen.

image_url string
The image URL to guide video generation.

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

OviI2VResponse
#
video File
The generated video file.

seed integer
The seed used for generation.

fal-ai/luma-dream-machine

Text to Video
Generate video clips from your prompts using Luma Dream Machine v1.5
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Text To Video

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/luma-dream-machine", {
  input: {
    prompt: "A teddy bear in sunglasses playing electric guitar and dancing"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/luma-dream-machine", {
  input: {
    prompt: "A teddy bear in sunglasses playing electric guitar and dancing"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/luma-dream-machine", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/luma-dream-machine", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)


{
  "prompt": "A teddy bear in sunglasses playing electric guitar and dancing",
  "aspect_ratio": "16:9"
}
Output
#
video File
The generated video


{
  "video": {
    "url": "https://v2.fal.media/files/807e842c734f4127a36de9262a2d292c_output.mp4"
  }
}
Other types
#
Ray2TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video (9s costs 2x more) Default value: "5s"

Possible enum values: 5s, 9s

ReframeVideoRequest
#
video_url string
URL of the input video to reframe

aspect_ratio AspectRatioEnum
The aspect ratio of the reframed video

Possible enum values: 1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

image_url string
Optional URL of the first frame image for reframing

grid_position_x integer
X position of the grid for reframing

grid_position_y integer
Y position of the grid for reframing

prompt string
Optional prompt for reframing

x_end integer
End X coordinate for reframing

x_start integer
Start X coordinate for reframing

y_end integer
End Y coordinate for reframing

y_start integer
Start Y coordinate for reframing

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
end_image_url string
An image to blend the end of the video with

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2ImageToVideoRequest
#
prompt string
image_url string
Initial image to start the video from. Can be used together with end_image_url.

end_image_url string
Final image to end the video with. Can be used together with image_url.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video Default value: "5s"

Possible enum values: 5s, 9s

ModifyVideoRequest
#
video_url string
URL of the input video to modify

image_url string
Optional URL of the first frame image for modification

prompt string
Instruction for modifying the video

mode ModeEnum
Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most Default value: "flex_1"

Possible enum values: adhere_1, adhere_2, adhere_3, flex_1, flex_2, flex_3, reimagine_1, reimagine_2, reimagine_3

fal-ai/luma-dream-machine/image-to-video

Image to Video
Generate video clips from your images using Luma Dream Machine v1.5
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Image To Video

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/luma-dream-machine/image-to-video", {
  input: {
    prompt: "Low-angle shot of a majestic tiger prowling through a snowy landscape, leaving paw prints on the white blanket",
    image_url: "https://fal.media/files/koala/1oLY4Bjp4XdGBBTSsrGlE.jpeg"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/luma-dream-machine/image-to-video", {
  input: {
    prompt: "Low-angle shot of a majestic tiger prowling through a snowy landscape, leaving paw prints on the white blanket",
    image_url: "https://fal.media/files/koala/1oLY4Bjp4XdGBBTSsrGlE.jpeg"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/luma-dream-machine/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/luma-dream-machine/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
image_url string
end_image_url string
An image to blend the end of the video with

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)


{
  "prompt": "Low-angle shot of a majestic tiger prowling through a snowy landscape, leaving paw prints on the white blanket",
  "image_url": "https://fal.media/files/koala/1oLY4Bjp4XdGBBTSsrGlE.jpeg",
  "aspect_ratio": "16:9"
}
Output
#
video File
The generated video


{
  "video": {
    "url": "https://v2.fal.media/files/8c216fcbc4ed41cd8840bd48c1ec6dd6_output.mp4"
  }
}
Other types
#
TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video (9s costs 2x more) Default value: "5s"

Possible enum values: 5s, 9s

ReframeVideoRequest
#
video_url string
URL of the input video to reframe

aspect_ratio AspectRatioEnum
The aspect ratio of the reframed video

Possible enum values: 1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

image_url string
Optional URL of the first frame image for reframing

grid_position_x integer
X position of the grid for reframing

grid_position_y integer
Y position of the grid for reframing

prompt string
Optional prompt for reframing

x_end integer
End X coordinate for reframing

x_start integer
Start X coordinate for reframing

y_end integer
End Y coordinate for reframing

y_start integer
Start Y coordinate for reframing

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

Ray2ImageToVideoRequest
#
prompt string
image_url string
Initial image to start the video from. Can be used together with end_image_url.

end_image_url string
Final image to end the video with. Can be used together with image_url.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video Default value: "5s"

Possible enum values: 5s, 9s

ModifyVideoRequest
#
video_url string
URL of the input video to modify

image_url string
Optional URL of the first frame image for modification

prompt string
Instruction for modifying the video

mode ModeEnum
Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most Default value: "flex_1"

Possible enum values: adhere_1, adhere_2, adhere_3, flex_1, flex_2, flex_3, reimagine_1, reimagine_2, reimagine_3

fal-ai/luma-dream-machine/ray-2

Text to Video (Ray 2)
Ray2 is a large-scale video generative model capable of creating realistic visuals with natural, coherent motion.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Luma's state of the art Ray2 model for text-to-video generation.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/luma-dream-machine/ray-2", {
  input: {
    prompt: "A herd of wild horses galloping across a dusty desert plain under a blazing midday sun, their manes flying in the wind; filmed in a wide tracking shot with dynamic motion, warm natural lighting, and an epic."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/luma-dream-machine/ray-2", {
  input: {
    prompt: "A herd of wild horses galloping across a dusty desert plain under a blazing midday sun, their manes flying in the wind; filmed in a wide tracking shot with dynamic motion, warm natural lighting, and an epic."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/luma-dream-machine/ray-2", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/luma-dream-machine/ray-2", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video (9s costs 2x more) Default value: "5s"

Possible enum values: 5s, 9s


{
  "prompt": "A herd of wild horses galloping across a dusty desert plain under a blazing midday sun, their manes flying in the wind; filmed in a wide tracking shot with dynamic motion, warm natural lighting, and an epic.",
  "aspect_ratio": "16:9",
  "resolution": "540p",
  "duration": "5s"
}
Output
#
video File
The generated video


{
  "video": {
    "url": "https://v3.fal.media/files/penguin/Om3xjcOwiSCJwrXs7DUi__output.mp4"
  }
}
Other types
#
TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

ReframeVideoRequest
#
video_url string
URL of the input video to reframe

aspect_ratio AspectRatioEnum
The aspect ratio of the reframed video

Possible enum values: 1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

image_url string
Optional URL of the first frame image for reframing

grid_position_x integer
X position of the grid for reframing

grid_position_y integer
Y position of the grid for reframing

prompt string
Optional prompt for reframing

x_end integer
End X coordinate for reframing

x_start integer
Start X coordinate for reframing

y_end integer
End Y coordinate for reframing

y_start integer
Start Y coordinate for reframing

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
end_image_url string
An image to blend the end of the video with

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2ImageToVideoRequest
#
prompt string
image_url string
Initial image to start the video from. Can be used together with end_image_url.

end_image_url string
Final image to end the video with. Can be used together with image_url.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video Default value: "5s"

Possible enum values: 5s, 9s

ModifyVideoRequest
#
video_url string
URL of the input video to modify

image_url string
Optional URL of the first frame image for modification

prompt string
Instruction for modifying the video

mode ModeEnum
Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most Default value: "flex_1"

Possible enum values: adhere_1, adhere_2, adhere_3, flex_1, flex_2, flex_3, reimagine_1, reimagine_2, reimagine_3

fal-ai/luma-dream-machine/ray-2-flash

Text to Video (Ray 2 Flash)
Ray2 Flash is a fast video generative model capable of creating realistic visuals with natural, coherent motion.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Luma's state of the art Ray2 model for text-to-video generation.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/luma-dream-machine/ray-2-flash", {
  input: {
    prompt: "A herd of wild horses galloping across a dusty desert plain under a blazing midday sun, their manes flying in the wind; filmed in a wide tracking shot with dynamic motion, warm natural lighting, and an epic."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/luma-dream-machine/ray-2-flash", {
  input: {
    prompt: "A herd of wild horses galloping across a dusty desert plain under a blazing midday sun, their manes flying in the wind; filmed in a wide tracking shot with dynamic motion, warm natural lighting, and an epic."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/luma-dream-machine/ray-2-flash", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/luma-dream-machine/ray-2-flash", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video (9s costs 2x more) Default value: "5s"

Possible enum values: 5s, 9s


{
  "prompt": "A herd of wild horses galloping across a dusty desert plain under a blazing midday sun, their manes flying in the wind; filmed in a wide tracking shot with dynamic motion, warm natural lighting, and an epic.",
  "aspect_ratio": "16:9",
  "resolution": "540p",
  "duration": "5s"
}
Output
#
video File
The generated video


{
  "video": {
    "url": "https://v3.fal.media/files/penguin/Om3xjcOwiSCJwrXs7DUi__output.mp4"
  }
}
Other types
#
TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

ReframeVideoRequest
#
video_url string
URL of the input video to reframe

aspect_ratio AspectRatioEnum
The aspect ratio of the reframed video

Possible enum values: 1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

image_url string
Optional URL of the first frame image for reframing

grid_position_x integer
X position of the grid for reframing

grid_position_y integer
Y position of the grid for reframing

prompt string
Optional prompt for reframing

x_end integer
End X coordinate for reframing

x_start integer
Start X coordinate for reframing

y_end integer
End Y coordinate for reframing

y_start integer
Start Y coordinate for reframing

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
end_image_url string
An image to blend the end of the video with

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2ImageToVideoRequest
#
prompt string
image_url string
Initial image to start the video from. Can be used together with end_image_url.

end_image_url string
Final image to end the video with. Can be used together with image_url.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video Default value: "5s"

Possible enum values: 5s, 9s

ModifyVideoRequest
#
video_url string
URL of the input video to modify

image_url string
Optional URL of the first frame image for modification

prompt string
Instruction for modifying the video

mode ModeEnum
Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most Default value: "flex_1"

Possible enum values: adhere_1, adhere_2, adhere_3, flex_1, flex_2, flex_3, reimagine_1, reimagine_2, reimagine_3

fal-ai/luma-dream-machine/ray-2-flash/image-to-video

Image to Video (Ray 2 Flash)
Ray2 Flash is a fast video generative model capable of creating realistic visuals with natural, coherent motion.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Luma's state of the art Ray2 model for image-to-video generation.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/luma-dream-machine/ray-2-flash/image-to-video", {
  input: {
    prompt: "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/luma-dream-machine/ray-2-flash/image-to-video", {
  input: {
    prompt: "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/luma-dream-machine/ray-2-flash/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/luma-dream-machine/ray-2-flash/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
image_url string
Initial image to start the video from. Can be used together with end_image_url.

end_image_url string
Final image to end the video with. Can be used together with image_url.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video Default value: "5s"

Possible enum values: 5s, 9s


{
  "prompt": "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage.",
  "image_url": "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg",
  "aspect_ratio": "16:9",
  "resolution": "540p",
  "duration": "5s"
}
Output
#
video File
URL of the generated video


{
  "video": {
    "url": "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4"
  }
}
Other types
#
TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video (9s costs 2x more) Default value: "5s"

Possible enum values: 5s, 9s

ReframeVideoRequest
#
video_url string
URL of the input video to reframe

aspect_ratio AspectRatioEnum
The aspect ratio of the reframed video

Possible enum values: 1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

image_url string
Optional URL of the first frame image for reframing

grid_position_x integer
X position of the grid for reframing

grid_position_y integer
Y position of the grid for reframing

prompt string
Optional prompt for reframing

x_end integer
End X coordinate for reframing

x_start integer
Start X coordinate for reframing

y_end integer
End Y coordinate for reframing

y_start integer
Start Y coordinate for reframing

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
end_image_url string
An image to blend the end of the video with

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

ModifyVideoRequest
#
video_url string
URL of the input video to modify

image_url string
Optional URL of the first frame image for modification

prompt string
Instruction for modifying the video

mode ModeEnum
Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most Default value: "flex_1"

Possible enum values: adhere_1, adhere_2, adhere_3, flex_1, flex_2, flex_3, reimagine_1, reimagine_2, reimagine_3

fal-ai/luma-dream-machine/ray-2-flash/modify

Ray-2 Flash (Modify)
Ray2 Flash Modify is a video generative model capable of restyling or retexturing the entire shot, from turning live-action into CG or stylized animation, to changing wardrobe, props, or the overall aesthetic and swap environments or time periods, giving you control over background, location, or even weather.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Ray2 Flash Modify Video

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/luma-dream-machine/ray-2-flash/modify", {
  input: {
    video_url: "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/luma-dream-machine/ray-2-flash/modify", {
  input: {
    video_url: "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/luma-dream-machine/ray-2-flash/modify", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/luma-dream-machine/ray-2-flash/modify", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
video_url string
URL of the input video to modify

image_url string
Optional URL of the first frame image for modification

prompt string
Instruction for modifying the video

mode ModeEnum
Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most Default value: "flex_1"

Possible enum values: adhere_1, adhere_2, adhere_3, flex_1, flex_2, flex_3, reimagine_1, reimagine_2, reimagine_3


{
  "video_url": "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4",
  "image_url": "https://fal.media/files/koala/Kv2821G03ggpKK2AiZX71_d5fa7bacf06049cfaeb9588f6003b6d5.jpg",
  "mode": "flex_1"
}
Output
#
video File
URL of the modified video


{
  "video": {
    "url": "https://v3.fal.media/files/lion/_2UO2QC26T_R8vKeVGAdX_output.mp4"
  }
}
Other types
#
TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video (9s costs 2x more) Default value: "5s"

Possible enum values: 5s, 9s

ReframeVideoRequest
#
video_url string
URL of the input video to reframe

aspect_ratio AspectRatioEnum
The aspect ratio of the reframed video

Possible enum values: 1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

image_url string
Optional URL of the first frame image for reframing

grid_position_x integer
X position of the grid for reframing

grid_position_y integer
Y position of the grid for reframing

prompt string
Optional prompt for reframing

x_end integer
End X coordinate for reframing

x_start integer
Start X coordinate for reframing

y_end integer
End Y coordinate for reframing

y_start integer
Start Y coordinate for reframing

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
end_image_url string
An image to blend the end of the video with

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2ImageToVideoRequest
#
prompt string
image_url string
Initial image to start the video from. Can be used together with end_image_url.

end_image_url string
Final image to end the video with. Can be used together with image_url.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video Default value: "5s"

Possible enum values: 5s, 9s

fal-ai/luma-dream-machine/ray-2-flash/reframe

Reframe (Ray 2 Flash)
Adjust and enhance videos with Ray-2 Reframe. This advanced tool seamlessly reframes videos to your desired aspect ratio, intelligently inpainting missing regions to ensure realistic visuals and coherent motion, delivering exceptional quality and creative flexibility.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Ray2 Flash Reframe Video

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/luma-dream-machine/ray-2-flash/reframe", {
  input: {
    video_url: "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4",
    aspect_ratio: "9:16"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/luma-dream-machine/ray-2-flash/reframe", {
  input: {
    video_url: "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4",
    aspect_ratio: "9:16"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/luma-dream-machine/ray-2-flash/reframe", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/luma-dream-machine/ray-2-flash/reframe", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
video_url string
URL of the input video to reframe

aspect_ratio AspectRatioEnum
The aspect ratio of the reframed video

Possible enum values: 1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

image_url string
Optional URL of the first frame image for reframing

grid_position_x integer
X position of the grid for reframing

grid_position_y integer
Y position of the grid for reframing

prompt string
Optional prompt for reframing

x_end integer
End X coordinate for reframing

x_start integer
Start X coordinate for reframing

y_end integer
End Y coordinate for reframing

y_start integer
Start Y coordinate for reframing


{
  "video_url": "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4",
  "aspect_ratio": "9:16"
}
Output
#
video File
URL of the reframed video


{
  "video": {
    "url": "https://v3.fal.media/files/lion/L9nkXSW1MCj2oDimeJ4w5_output.mp4"
  }
}
Other types
#
TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video (9s costs 2x more) Default value: "5s"

Possible enum values: 5s, 9s

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
end_image_url string
An image to blend the end of the video with

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2ImageToVideoRequest
#
prompt string
image_url string
Initial image to start the video from. Can be used together with end_image_url.

end_image_url string
Final image to end the video with. Can be used together with image_url.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video Default value: "5s"

Possible enum values: 5s, 9s

ModifyVideoRequest
#
video_url string
URL of the input video to modify

image_url string
Optional URL of the first frame image for modification

prompt string
Instruction for modifying the video

mode ModeEnum
Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most Default value: "flex_1"

Possible enum values: adhere_1, adhere_2, adhere_3, flex_1, flex_2, flex_3, reimagine_1, reimagine_2, reimagine_3

fal-ai/luma-dream-machine/ray-2/image-to-video

Image to Video (Ray 2)
Ray2 is a large-scale video generative model capable of creating realistic visuals with natural, coherent motion.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Luma's state of the art Ray2 model for image-to-video generation.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/luma-dream-machine/ray-2/image-to-video", {
  input: {
    prompt: "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/luma-dream-machine/ray-2/image-to-video", {
  input: {
    prompt: "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/luma-dream-machine/ray-2/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/luma-dream-machine/ray-2/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
image_url string
Initial image to start the video from. Can be used together with end_image_url.

end_image_url string
Final image to end the video with. Can be used together with image_url.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video Default value: "5s"

Possible enum values: 5s, 9s


{
  "prompt": "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage.",
  "image_url": "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg",
  "aspect_ratio": "16:9",
  "resolution": "540p",
  "duration": "5s"
}
Output
#
video File
URL of the generated video


{
  "video": {
    "url": "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4"
  }
}
Other types
#
TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video (9s costs 2x more) Default value: "5s"

Possible enum values: 5s, 9s

ReframeVideoRequest
#
video_url string
URL of the input video to reframe

aspect_ratio AspectRatioEnum
The aspect ratio of the reframed video

Possible enum values: 1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

image_url string
Optional URL of the first frame image for reframing

grid_position_x integer
X position of the grid for reframing

grid_position_y integer
Y position of the grid for reframing

prompt string
Optional prompt for reframing

x_end integer
End X coordinate for reframing

x_start integer
Start X coordinate for reframing

y_end integer
End Y coordinate for reframing

y_start integer
Start Y coordinate for reframing

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
end_image_url string
An image to blend the end of the video with

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

ModifyVideoRequest
#
video_url string
URL of the input video to modify

image_url string
Optional URL of the first frame image for modification

prompt string
Instruction for modifying the video

mode ModeEnum
Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most Default value: "flex_1"

Possible enum values: adhere_1, adhere_2, adhere_3, flex_1, flex_2, flex_3, reimagine_1, reimagine_2, reimagine_3

fal-ai/luma-dream-machine/ray-2/modify

Ray-2 (Modify)
Ray2 Modify is a video generative model capable of restyling or retexturing the entire shot, from turning live-action into CG or stylized animation, to changing wardrobe, props, or the overall aesthetic and swap environments or time periods, giving you control over background, location, or even weather.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Ray2 Modify Video

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/luma-dream-machine/ray-2/modify", {
  input: {
    video_url: "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/luma-dream-machine/ray-2/modify", {
  input: {
    video_url: "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/luma-dream-machine/ray-2/modify", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/luma-dream-machine/ray-2/modify", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
video_url string
URL of the input video to modify

image_url string
Optional URL of the first frame image for modification

prompt string
Instruction for modifying the video

mode ModeEnum
Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most Default value: "flex_1"

Possible enum values: adhere_1, adhere_2, adhere_3, flex_1, flex_2, flex_3, reimagine_1, reimagine_2, reimagine_3


{
  "video_url": "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4",
  "image_url": "https://fal.media/files/koala/Kv2821G03ggpKK2AiZX71_d5fa7bacf06049cfaeb9588f6003b6d5.jpg",
  "mode": "flex_1"
}
Output
#
video File
URL of the modified video


{
  "video": {
    "url": "https://v3.fal.media/files/lion/_2UO2QC26T_R8vKeVGAdX_output.mp4"
  }
}
Other types
#
TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video (9s costs 2x more) Default value: "5s"

Possible enum values: 5s, 9s

ReframeVideoRequest
#
video_url string
URL of the input video to reframe

aspect_ratio AspectRatioEnum
The aspect ratio of the reframed video

Possible enum values: 1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

image_url string
Optional URL of the first frame image for reframing

grid_position_x integer
X position of the grid for reframing

grid_position_y integer
Y position of the grid for reframing

prompt string
Optional prompt for reframing

x_end integer
End X coordinate for reframing

x_start integer
Start X coordinate for reframing

y_end integer
End Y coordinate for reframing

y_start integer
Start Y coordinate for reframing

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
end_image_url string
An image to blend the end of the video with

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2ImageToVideoRequest
#
prompt string
image_url string
Initial image to start the video from. Can be used together with end_image_url.

end_image_url string
Final image to end the video with. Can be used together with image_url.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video Default value: "5s"

Possible enum values: 5s, 9s

fal-ai/luma-dream-machine/ray-2/reframe

Reframe (Ray 2)
Adjust and enhance videos with Ray-2 Reframe. This advanced tool seamlessly reframes videos to your desired aspect ratio, intelligently inpainting missing regions to ensure realistic visuals and coherent motion, delivering exceptional quality and creative flexibility.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Ray2 Reframe Video

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/luma-dream-machine/ray-2/reframe", {
  input: {
    video_url: "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4",
    aspect_ratio: "9:16"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/luma-dream-machine/ray-2/reframe", {
  input: {
    video_url: "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4",
    aspect_ratio: "9:16"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/luma-dream-machine/ray-2/reframe", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/luma-dream-machine/ray-2/reframe", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
video_url string
URL of the input video to reframe

aspect_ratio AspectRatioEnum
The aspect ratio of the reframed video

Possible enum values: 1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

image_url string
Optional URL of the first frame image for reframing

grid_position_x integer
X position of the grid for reframing

grid_position_y integer
Y position of the grid for reframing

prompt string
Optional prompt for reframing

x_end integer
End X coordinate for reframing

x_start integer
Start X coordinate for reframing

y_end integer
End Y coordinate for reframing

y_start integer
Start Y coordinate for reframing


{
  "video_url": "https://v3.fal.media/files/zebra/9aDde3Te2kuJYHdR0Kz8R_output.mp4",
  "aspect_ratio": "9:16"
}
Output
#
video File
URL of the reframed video


{
  "video": {
    "url": "https://v3.fal.media/files/lion/L9nkXSW1MCj2oDimeJ4w5_output.mp4"
  }
}
Other types
#
TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2TextToVideoRequest
#
prompt string
aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video (9s costs 2x more) Default value: "5s"

Possible enum values: 5s, 9s

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ImageToVideoRequest
#
prompt string
image_url string
end_image_url string
An image to blend the end of the video with

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

Ray2ImageToVideoRequest
#
prompt string
image_url string
Initial image to start the video from. Can be used together with end_image_url.

end_image_url string
Final image to end the video with. Can be used together with image_url.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video Default value: "16:9"

Possible enum values: 16:9, 9:16, 4:3, 3:4, 21:9, 9:21

loop boolean
Whether the video should loop (end of video is blended with the beginning)

resolution ResolutionEnum
The resolution of the generated video (720p costs 2x more, 1080p costs 4x more) Default value: "540p"

Possible enum values: 540p, 720p, 1080p

duration DurationEnum
The duration of the generated video Default value: "5s"

Possible enum values: 5s, 9s

ModifyVideoRequest
#
video_url string
URL of the input video to modify

image_url string
Optional URL of the first frame image for modification

prompt string
Instruction for modifying the video

mode ModeEnum
Amount of modification to apply to the video, adhere_1 is the least amount of modification, reimagine_3 is the most Default value: "flex_1"

Possible enum values: adhere_1, adhere_2, adhere_3, flex_1, flex_2, flex_3, reimagine_1, reimagine_2, reimagine_3

fal-ai/flux-kontext-lora/inpaint

Image Inpainting
Fast inpainting endpoint for the FLUX.1 Kontext [dev] model with LoRA support, enabling rapid and high-quality image inpainting with reference images, while using pre-trained LoRA adaptations for specific styles, brand identities, and product-specific outputs.
Inference
Commercial use
Streaming
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
FLUX.1 Kontext, perform inpainting operations with the FLUX.1 Kontext model.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/flux-kontext-lora/inpaint", {
  input: {
    image_url: "https://storage.googleapis.com/falserverless/example_inputs/image_kontext_inpaint.jpeg",
    prompt: "A football lying on a field.",
    reference_image_url: "https://storage.googleapis.com/falserverless/example_inputs/reference_kontext_inpaint.jpeg",
    mask_url: "https://storage.googleapis.com/falserverless/example_inputs/mask_kontext_inpaint.png"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
Streaming
#
This model supports streaming requests. You can stream data directly to the model and get the result in real-time.


import { fal } from "@fal-ai/client";

const stream = await fal.stream("fal-ai/flux-kontext-lora/inpaint", {
  input: {
    image_url: "https://storage.googleapis.com/falserverless/example_inputs/image_kontext_inpaint.jpeg",
    prompt: "A football lying on a field.",
    reference_image_url: "https://storage.googleapis.com/falserverless/example_inputs/reference_kontext_inpaint.jpeg",
    mask_url: "https://storage.googleapis.com/falserverless/example_inputs/mask_kontext_inpaint.png"
  }
});

for await (const event of stream) {
  console.log(event);
}

const result = await stream.done();
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/flux-kontext-lora/inpaint", {
  input: {
    image_url: "https://storage.googleapis.com/falserverless/example_inputs/image_kontext_inpaint.jpeg",
    prompt: "A football lying on a field.",
    reference_image_url: "https://storage.googleapis.com/falserverless/example_inputs/reference_kontext_inpaint.jpeg",
    mask_url: "https://storage.googleapis.com/falserverless/example_inputs/mask_kontext_inpaint.png"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/flux-kontext-lora/inpaint", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/flux-kontext-lora/inpaint", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
image_url string
The URL of the image to be inpainted.

prompt string
The prompt for the image to image task.

num_inference_steps integer
The number of inference steps to perform. Default value: 30

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 2.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

output_format OutputFormatEnum
The format of the generated image. Default value: "png"

Possible enum values: jpeg, png

loras list<LoraWeight>
The LoRAs to use for the image generation. You can use any number of LoRAs and they will be merged together to generate the final image.

acceleration AccelerationEnum
The speed of the generation. The higher the speed, the faster the generation. Default value: "none"

Possible enum values: none, regular, high

reference_image_url string
The URL of the reference image for inpainting.

mask_url string
The URL of the mask for inpainting.

strength float
The strength of the initial image. Higher strength values are better for this model. Default value: 0.88


{
  "image_url": "https://storage.googleapis.com/falserverless/example_inputs/image_kontext_inpaint.jpeg",
  "prompt": "A football lying on a field.",
  "num_inference_steps": 30,
  "guidance_scale": 2.5,
  "num_images": 1,
  "enable_safety_checker": true,
  "output_format": "png",
  "acceleration": "none",
  "reference_image_url": "https://storage.googleapis.com/falserverless/example_inputs/reference_kontext_inpaint.jpeg",
  "mask_url": "https://storage.googleapis.com/falserverless/example_inputs/mask_kontext_inpaint.png",
  "strength": 0.88
}
Output
#
images list<Image>
The generated image files info.

timings Timings
seed integer
Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.

has_nsfw_concepts list<boolean>
Whether the generated images contain NSFW concepts.

prompt string
The prompt used for generating the image.


{
  "images": [
    {
      "height": 832,
      "content_type": "image/jpeg",
      "url": "https://storage.googleapis.com/falserverless/example_outputs/kontext_inpaint_output.png",
      "width": 1248
    }
  ],
  "prompt": ""
}
Other types
#
LoraWeight
#
path string
URL or the path to the LoRA weights.

scale float
The scale of the LoRA weight. This is used to scale the LoRA weight before merging it with the base model. Default value: 1

Image
#
url string
width integer
height integer
content_type string
Default value: "image/jpeg"

ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512

fal-ai/flux-kontext-lora

Image Editing
Fast endpoint for the FLUX.1 Kontext [dev] model with LoRA support, enabling rapid and high-quality image editing using pre-trained LoRA adaptations for specific styles, brand identities, and product-specific outputs.
Inference
Commercial use
Streaming
Schema
LLMs


Training
Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
FLUX.1 Kontext [dev] -- Frontier image editing model.

Kontext makes editing images easy! Specify what you want to change and Kontext will follow. It is capable of understanding the context of the image, making it easier to edit them without having to describe in details what you want to do.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/flux-kontext-lora", {
  input: {
    image_url: "https://storage.googleapis.com/falserverless/example_inputs/kontext_example_input.webp",
    prompt: "change the setting to a day time, add a lot of people walking the sidewalk while maintaining the same style of the painting"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
Streaming
#
This model supports streaming requests. You can stream data directly to the model and get the result in real-time.


import { fal } from "@fal-ai/client";

const stream = await fal.stream("fal-ai/flux-kontext-lora", {
  input: {
    image_url: "https://storage.googleapis.com/falserverless/example_inputs/kontext_example_input.webp",
    prompt: "change the setting to a day time, add a lot of people walking the sidewalk while maintaining the same style of the painting"
  }
});

for await (const event of stream) {
  console.log(event);
}

const result = await stream.done();
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/flux-kontext-lora", {
  input: {
    image_url: "https://storage.googleapis.com/falserverless/example_inputs/kontext_example_input.webp",
    prompt: "change the setting to a day time, add a lot of people walking the sidewalk while maintaining the same style of the painting"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/flux-kontext-lora", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/flux-kontext-lora", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
image_url string
The URL of the image to edit.

Max width: 14142px, Max height: 14142px, Timeout: 20s

prompt string
The prompt to edit the image.

num_inference_steps integer
The number of inference steps to perform. Default value: 30

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 2.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

output_format OutputFormatEnum
The format of the generated image. Default value: "png"

Possible enum values: jpeg, png

loras list<LoraWeight>
The LoRAs to use for the image generation. You can use any number of LoRAs and they will be merged together to generate the final image.

acceleration AccelerationEnum
The speed of the generation. The higher the speed, the faster the generation. Default value: "none"

Possible enum values: none, regular, high

resolution_mode ResolutionModeEnum
Determines how the output resolution is set for image editing.

auto: The model selects an optimal resolution from a predefined set that best matches the input image's aspect ratio. This is the recommended setting for most use cases as it's what the model was trained on.
match_input: The model will attempt to use the same resolution as the input image. The resolution will be adjusted to be compatible with the model's requirements (e.g. dimensions must be multiples of 16 and within supported limits). Apart from these, a few aspect ratios are also supported. Default value: "match_input"
Possible enum values: auto, match_input, 1:1, 16:9, 21:9, 3:2, 2:3, 4:5, 5:4, 3:4, 4:3, 9:16, 9:21


{
  "image_url": "https://storage.googleapis.com/falserverless/example_inputs/kontext_example_input.webp",
  "prompt": "change the setting to a day time, add a lot of people walking the sidewalk while maintaining the same style of the painting",
  "num_inference_steps": 30,
  "guidance_scale": 2.5,
  "num_images": 1,
  "enable_safety_checker": true,
  "output_format": "png",
  "acceleration": "none",
  "resolution_mode": "match_input"
}
Output
#
images list<Image>
The generated image files info.

timings Timings
seed integer
Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.

has_nsfw_concepts list<boolean>
Whether the generated images contain NSFW concepts.

prompt string
The prompt used for generating the image.


{
  "images": [
    {
      "height": 768,
      "content_type": "image/jpeg",
      "url": "https://storage.googleapis.com/falserverless/example_outputs/kontext_example_output.jpeg",
      "width": 1024
    }
  ],
  "prompt": ""
}
Other types
#
LoraWeight
#
path string
URL or the path to the LoRA weights.

scale float
The scale of the LoRA weight. This is used to scale the LoRA weight before merging it with the base model. Default value: 1

Image
#
url string
width integer
height integer
content_type string
Default value: "image/jpeg"

ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512

fal-ai/flux-kontext-lora/text-to-image

Text to Image
Super fast text-to-image endpoint for the FLUX.1 Kontext [dev] model with LoRA support, enabling rapid and high-quality image generation using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.
Inference
Commercial use
Streaming
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
FLUX.1 Kontext, generate images with the FLUX.1 Kontext model.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/flux-kontext-lora/text-to-image", {
  input: {
    prompt: "Mount Fuji with cherry blossoms in the foreground, clear sky, peaceful spring day, soft natural light, realistic landscape."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
Streaming
#
This model supports streaming requests. You can stream data directly to the model and get the result in real-time.


import { fal } from "@fal-ai/client";

const stream = await fal.stream("fal-ai/flux-kontext-lora/text-to-image", {
  input: {
    prompt: "Mount Fuji with cherry blossoms in the foreground, clear sky, peaceful spring day, soft natural light, realistic landscape."
  }
});

for await (const event of stream) {
  console.log(event);
}

const result = await stream.done();
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/flux-kontext-lora/text-to-image", {
  input: {
    prompt: "Mount Fuji with cherry blossoms in the foreground, clear sky, peaceful spring day, soft natural light, realistic landscape."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/flux-kontext-lora/text-to-image", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/flux-kontext-lora/text-to-image", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The prompt to generate the image with

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 30

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 2.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

output_format OutputFormatEnum
The format of the generated image. Default value: "png"

Possible enum values: jpeg, png

loras list<LoraWeight>
The LoRAs to use for the image generation. You can use any number of LoRAs and they will be merged together to generate the final image.

acceleration AccelerationEnum
The speed of the generation. The higher the speed, the faster the generation. Default value: "none"

Possible enum values: none, regular, high


{
  "prompt": "Mount Fuji with cherry blossoms in the foreground, clear sky, peaceful spring day, soft natural light, realistic landscape.",
  "image_size": "landscape_4_3",
  "num_inference_steps": 30,
  "guidance_scale": 2.5,
  "num_images": 1,
  "enable_safety_checker": true,
  "output_format": "png",
  "acceleration": "none"
}
Output
#
images list<Image>
The generated image files info.

timings Timings
seed integer
Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.

has_nsfw_concepts list<boolean>
Whether the generated images contain NSFW concepts.

prompt string
The prompt used for generating the image.


{
  "images": [
    {
      "height": 768,
      "content_type": "image/jpeg",
      "url": "https://storage.googleapis.com/falserverless/example_outputs/kontext_example_t2i_output.png",
      "width": 1024
    }
  ],
  "prompt": ""
}
Other types
#
LoraWeight
#
path string
URL or the path to the LoRA weights.

scale float
The scale of the LoRA weight. This is used to scale the LoRA weight before merging it with the base model. Default value: 1

Image
#
url string
width integer
height integer
content_type string
Default value: "image/jpeg"

ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512


fal-ai/minimax-music/v1.5

v1.5
Generate music from text prompts using the MiniMax model, which leverages advanced AI techniques to create high-quality, diverse musical compositions.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Text To Music V1 5

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/minimax-music/v1.5", {
  input: {
    prompt: "[verse]
   Fast and Limitless
   In the heart of the code, where dreams collide,

  FAL's the name, taking tech for a ride.
  Generative media, blazing the trail,

  Fast inference power, we'll never fail.
  ##",
    lyrics_prompt: "R&B, energetic"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/minimax-music/v1.5", {
  input: {
    prompt: "[verse]
   Fast and Limitless
   In the heart of the code, where dreams collide,

  FAL's the name, taking tech for a ride.
  Generative media, blazing the trail,

  Fast inference power, we'll never fail.
  ##",
    lyrics_prompt: "R&B, energetic"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/minimax-music/v1.5", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/minimax-music/v1.5", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
Lyrics, supports [intro][verse][chorus][bridge][outro] sections. 10-600 characters.

audio_setting AudioSetting
Audio configuration settings

lyrics_prompt string
Control music generation. 10-300 characters.


{
  "prompt": "[verse]\n Fast and Limitless   \n In the heart of the code, where dreams collide,   \n\nFAL's the name, taking tech for a ride.    \nGenerative media, blazing the trail,   \n\nFast inference power, we'll never fail.\n##",
  "lyrics_prompt": "R&B, energetic"
}
Output
#
audio File
The generated music


{
  "audio": {
    "url": "https://v3.fal.media/files/lion/b3-wJ5bbmVo8S-KPqDBMK_output.mp3"
  }
}
Other types
#
AudioSetting
#
sample_rate SampleRateEnum
Sample rate of generated audio Default value: "44100"

Possible enum values: 8000, 16000, 22050, 24000, 32000, 44100

bitrate BitrateEnum
Bitrate of generated audio Default value: "256000"

Possible enum values: 32000, 64000, 128000, 256000

format FormatEnum
Audio format Default value: "mp3"

Possible enum values: mp3, pcm, flac

TextToMusicRequest
#
prompt string
Lyrics with optional formatting. You can use a newline to separate each line of lyrics. You can use two newlines to add a pause between lines. You can use double hash marks (##) at the beginning and end of the lyrics to add accompaniment. Maximum 600 characters.

reference_audio_url string
Reference song, should contain music and vocals. Must be a .wav or .mp3 file longer than 15 seconds.

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data


Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
A description of the track you want to generate. This prompt will be used to automatically generate the tags and lyrics unless you manually set them. For example, if you set prompt and tags, then the prompt will be used to generate only the lyrics.

tags list<string>
Tags/styles of the music to generate. You can view a list of all available tags at https://sonauto.ai/tag-explorer.

lyrics_prompt string
The lyrics sung in the generated song. An empty string will generate an instrumental track.

seed integer
The seed to use for generation. Will pick a random seed if not provided. Repeating a request with identical parameters (must use lyrics and tags, not prompt) and the same seed will generate the same song.

prompt_strength float
Controls how strongly your prompt influences the output. Greater values adhere more to the prompt but sound less natural. (This is CFG.) Default value: 2

balance_strength float
Greater means more natural vocals. Lower means sharper instrumentals. We recommend 0.7. Default value: 0.7

num_songs integer
Generating 2 songs costs 1.5x the price of generating 1 song. Also, note that using the same seed may not result in identical songs if the number of songs generated is changed. Default value: 1

output_format OutputFormatEnum
Default value: "wav"

Possible enum values: flac, mp3, wav, ogg, m4a

output_bit_rate Enum
The bit rate to use for mp3 and m4a formats. Not available for other formats.

Possible enum values: 128, 192, 256, 320

bpm integer | string
The beats per minute of the song. This can be set to an integer or the literal string "auto" to pick a suitable bpm based on the tags. Set bpm to null to not condition the model on bpm information. Default value: auto


{
  "prompt": "A pop song about turtles flying",
  "prompt_strength": 2,
  "balance_strength": 0.7,
  "num_songs": 1,
  "output_format": "wav",
  "bpm": "auto"
}
Output
#
seed integer
The seed used for generation. This can be used to generate an identical song by passing the same parameters with this seed in a future request.

tags list<string>
The style tags used for generation.

lyrics string
The lyrics used for generation.

audio list<File>
The generated audio files.


{
  "seed": 42,
  "audio": {
    "file_size": 16777294,
    "file_name": "sonauto.wav",
    "content_type": "audio/wav",
    "url": "https://cdn.sonauto.ai/generations2_altformats/audio_c5e63f7c-fc79-4322-808d-c09911af4713.wav"
  }
}
Other types
#
InpaintSection
#
start float
Start time in seconds of the section to inpaint.

end float
End time in seconds of the section to inpaint.

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.


fal-ai/minimax-music

Generate music from text prompts using the MiniMax model, which leverages advanced AI techniques to create high-quality, diverse musical compositions.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Text To Music

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/minimax-music", {
  input: {
    prompt: "## Fast and Limitless
   In the heart of the code, where dreams collide,

  FAL's the name, taking tech for a ride.
  Generative media, blazing the trail,

  Fast inference power, we'll never fail.
  ##",
    reference_audio_url: "https://fal.media/files/lion/OOTBTSlxKMH_E8H6hoSlb.mpga"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/minimax-music", {
  input: {
    prompt: "## Fast and Limitless
   In the heart of the code, where dreams collide,

  FAL's the name, taking tech for a ride.
  Generative media, blazing the trail,

  Fast inference power, we'll never fail.
  ##",
    reference_audio_url: "https://fal.media/files/lion/OOTBTSlxKMH_E8H6hoSlb.mpga"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/minimax-music", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/minimax-music", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
Lyrics with optional formatting. You can use a newline to separate each line of lyrics. You can use two newlines to add a pause between lines. You can use double hash marks (##) at the beginning and end of the lyrics to add accompaniment. Maximum 600 characters.

reference_audio_url string
Reference song, should contain music and vocals. Must be a .wav or .mp3 file longer than 15 seconds.


{
  "prompt": "## Fast and Limitless   \n In the heart of the code, where dreams collide,   \n\nFAL's the name, taking tech for a ride.    \nGenerative media, blazing the trail,   \n\nFast inference power, we'll never fail.\n##",
  "reference_audio_url": "https://fal.media/files/lion/OOTBTSlxKMH_E8H6hoSlb.mpga"
}
Output
#
audio File
The generated music


{
  "audio": {
    "url": "https://fal.media/files/elephant/N5UNLCwkC2y8v7a3LQLFE_output.mp3"
  }
}
Other types
#
TextToMusic15Request
#
prompt string
Lyrics, supports [intro][verse][chorus][bridge][outro] sections. 10-600 characters.

audio_setting AudioSetting
Audio configuration settings

lyrics_prompt string
Control music generation. 10-300 characters.

AudioSetting
#
sample_rate SampleRateEnum
Sample rate of generated audio Default value: "44100"

Possible enum values: 8000, 16000, 22050, 24000, 32000, 44100

bitrate BitrateEnum
Bitrate of generated audio Default value: "256000"

Possible enum values: 32000, 64000, 128000, 256000

format FormatEnum
Audio format Default value: "mp3"

Possible enum values: mp3, pcm, flac

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string

al-ai/kling-video/video-to-audio

Generate audio from input videos using Kling
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Kling Video to Audio API. This endpoint extracts audio from a video file.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/kling-video/video-to-audio", {
  input: {
    video_url: "https://storage.googleapis.com/falserverless/model_tests/kling/kling-v2.5-turbo-pro-image-to-video-output.mp4"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/kling-video/video-to-audio", {
  input: {
    video_url: "https://storage.googleapis.com/falserverless/model_tests/kling/kling-v2.5-turbo-pro-image-to-video-output.mp4"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/kling-video/video-to-audio", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/kling-video/video-to-audio", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
video_url string
The video URL to extract audio from. Only .mp4/.mov formats are supported. File size does not exceed 100MB. Video duration between 3.0s and 20.0s.

sound_effect_prompt string
Sound effect prompt. Cannot exceed 200 characters. Default value: "Car tires screech as they accelerate in a drag race"

background_music_prompt string
Background music prompt. Cannot exceed 200 characters. Default value: "intense car race"

asmr_mode boolean
Enable ASMR mode. This mode enhances detailed sound effects and is suitable for highly immersive content scenarios.


{
  "video_url": "https://storage.googleapis.com/falserverless/model_tests/kling/kling-v2.5-turbo-pro-image-to-video-output.mp4",
  "sound_effect_prompt": "Car tires screech as they accelerate in a drag race",
  "background_music_prompt": "intense car race"
}
Output
#
video File
The original video with dubbed audio applied

audio File
The extracted/generated audio from the video in MP3 format


{
  "video": {
    "url": "https://v3.fal.media/files/monkey/O-ekVTtYqeDblD1oSf2uv_dubbed_video.mp4"
  },
  "audio": {
    "url": "https://v3.fal.media/files/monkey/O-ekVTtYqeDblD1oSf2uv_extracted_audio.mp3"
  }
}
Other types
#
TextToVideoV21MasterRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

ProImageToVideoRequest
#
prompt string
image_url string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

tail_image_url string
URL of the image to be used for the end of the video

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

V1TextToVideoRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

camera_control CameraControlEnum
Camera control parameters

Possible enum values: down_back, forward_up, right_turn_forward, left_turn_forward

advanced_camera_control CameraControl
Advanced Camera control parameters

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

TextToVideoV25ProRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

ImageToVideoRequest
#
prompt string
image_url string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

ImageToVideoV21MasterRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

LipsyncA2VRequest
#
video_url string
The URL of the video to generate the lip sync for. Supports .mp4/.mov, ≤100MB, 2–10s, 720p/1080p only, width/height 720–1920px.

audio_url string
The URL of the audio to generate the lip sync for. Minimum duration is 2s and maximum duration is 60s. Maximum file size is 5MB.

CameraControl
#
movement_type MovementTypeEnum
The type of camera movement

Possible enum values: horizontal, vertical, pan, tilt, roll, zoom

movement_value integer
The value of the camera movement

ImageToVideoV21StandardRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

TextToVideoRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

LipsyncT2VRequest
#
video_url string
The URL of the video to generate the lip sync for. Supports .mp4/.mov, ≤100MB, 2-60s, 720p/1080p only, width/height 720–1920px. If validation fails, an error is returned.

text string
Text content for lip-sync video generation. Max 120 characters.

voice_id VoiceIdEnum
Voice ID to use for speech synthesis

Possible enum values: genshin_vindi2, zhinen_xuesheng, AOT, ai_shatang, genshin_klee2, genshin_kirara, ai_kaiya, oversea_male1, ai_chenjiahao_712, girlfriend_4_speech02, chat1_female_new-3, chat_0407_5-1, cartoon-boy-07, uk_boy1, cartoon-girl-01, PeppaPig_platform, ai_huangzhong_712, ai_huangyaoshi_712, ai_laoguowang_712, chengshu_jiejie, you_pingjing, calm_story1, uk_man2, laopopo_speech02, heainainai_speech02, reader_en_m-v1, commercial_lady_en_f-v1, tiyuxi_xuedi, tiexin_nanyou, girlfriend_1_speech02, girlfriend_2_speech02, zhuxi_speech02, uk_oldman3, dongbeilaotie_speech02, chongqingxiaohuo_speech02, chuanmeizi_speech02, chaoshandashu_speech02, ai_taiwan_man2_speech02, xianzhanggui_speech02, tianjinjiejie_speech02, diyinnansang_DB_CN_M_04-v2, yizhipiannan-v1, guanxiaofang-v2, tianmeixuemei-v1, daopianyansang-v1, mengwa-v1

voice_language VoiceLanguageEnum
The voice language corresponding to the Voice ID Default value: "en"

Possible enum values: zh, en

voice_speed float
Speech rate for Text to Video generation Default value: 1

ImageToVideoV21ProRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

tail_image_url string
URL of the image to be used for the end of the video

DynamicMask
#
mask_url string
URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)

trajectories list<Trajectory>
List of trajectories

ImageToVideoV25ProRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

VideoEffectsRequest
#
input_image_urls list<string>
URL of images to be used for hug, kiss or heart_gesture video.

effect_scene EffectSceneEnum
The effect scene to use for the video generation

Possible enum values: hug, kiss, heart_gesture, squish, expansion, fuzzyfuzzy, bloombloom, dizzydizzy, jelly_press, jelly_slice, jelly_squish, jelly_jiggle, pixelpixel, yearbook, instant_film, anime_figure, rocketrocket

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

MultiImageToVideoRequest
#
prompt string
input_image_urls list<string>
List of image URLs to use for video generation. Supports up to 4 images.

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

V1ImageToVideoRequest
#
prompt string
The prompt for the video

image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

tail_image_url string
URL of the image to be used for the end of the video

static_mask_url string
URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)

dynamic_masks list<DynamicMask>
List of dynamic masks

TextToVideoV2MasterRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

Trajectory
#
x integer
X coordinate of the motion trajectory

y integer
Y coordinate of the motion trajectory

ImageToVideoV2MasterRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

fal-ai/meshy/v5/multi-image-to-3d

v5 Multi-Image to 3D
Meshy-5 multi image generates realistic and production ready 3D models from multiple images.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Convert multiple images to a 3D model using Meshy-5.

Multi-Image to 3D features:

Use 1-4 images of the same object from different angles
Better geometry reconstruction from multiple viewpoints
Only available with Meshy-5 model
Same texture options as single image-to-3D
Processing time: 3-7 minutes
For best results:

Use images of the same object from different angles
Ensure consistent lighting across images
Include front, side, and back views when possible
Note: If more than 4 images are provided, only the first 4 will be used.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/meshy/v5/multi-image-to-3d", {
  input: {
    image_urls: ["https://v3b.fal.media/files/b/kangaroo/cPyD3-por0XI7jDa9F9vP_image%20(3).png", "https://v3b.fal.media/files/b/elephant/9sd5JWAOJBcR7G3NMjPVs_image%20(2).png", "https://v3b.fal.media/files/b/tiger/TP4sTzPATX_w1Tn4m6kYM_image%20(1).png"]
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/meshy/v5/multi-image-to-3d", {
  input: {
    image_urls: ["https://v3b.fal.media/files/b/kangaroo/cPyD3-por0XI7jDa9F9vP_image%20(3).png", "https://v3b.fal.media/files/b/elephant/9sd5JWAOJBcR7G3NMjPVs_image%20(2).png", "https://v3b.fal.media/files/b/tiger/TP4sTzPATX_w1Tn4m6kYM_image%20(1).png"]
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/meshy/v5/multi-image-to-3d", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/meshy/v5/multi-image-to-3d", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
image_urls list<string>
1 to 4 images for 3D model creation. All images should depict the same object from different angles. Supports .jpg, .jpeg, .png formats, and AVIF/HEIF which will be automatically converted. If more than 4 images are provided, only the first 4 will be used.

topology TopologyEnum
Specify the topology of the generated model. Quad for smooth surfaces, Triangle for detailed geometry. Default value: "triangle"

Possible enum values: quad, triangle

target_polycount integer
Target number of polygons in the generated model Default value: 30000

symmetry_mode SymmetryModeEnum
Controls symmetry behavior during model generation. Default value: "auto"

Possible enum values: off, auto, on

should_remesh boolean
Whether to enable the remesh phase. When false, returns triangular mesh ignoring topology and target_polycount. Default value: true

should_texture boolean
Whether to generate textures. False provides mesh without textures for 5 credits, True adds texture generation for additional 10 credits. Default value: true

enable_pbr boolean
Generate PBR Maps (metallic, roughness, normal) in addition to base color. Requires should_texture to be true.

is_a_t_pose boolean
Whether to generate the model in an A/T pose

texture_prompt string
Text prompt to guide the texturing process. Requires should_texture to be true.

texture_image_url string
2D image to guide the texturing process. Requires should_texture to be true.

enable_safety_checker boolean
If set to true, input data will be checked for safety before processing. Default value: true


{
  "image_urls": [
    "https://v3b.fal.media/files/b/kangaroo/cPyD3-por0XI7jDa9F9vP_image%20(3).png",
    "https://v3b.fal.media/files/b/elephant/9sd5JWAOJBcR7G3NMjPVs_image%20(2).png",
    "https://v3b.fal.media/files/b/tiger/TP4sTzPATX_w1Tn4m6kYM_image%20(1).png"
  ],
  "topology": "triangle",
  "target_polycount": 30000,
  "symmetry_mode": "auto",
  "should_remesh": true,
  "should_texture": true,
  "enable_safety_checker": true
}
Output
#
model_glb File
Generated 3D object in GLB format.

thumbnail File
Preview thumbnail of the generated model

model_urls ModelUrls
URLs for different 3D model formats

texture_urls list<TextureFiles>
Array of texture file objects

seed integer
The seed used for generation (if available)


{
  "model_glb": {
    "file_size": 7875308,
    "file_name": "model.glb",
    "content_type": "model/gltf-binary",
    "url": "https://v3b.fal.media/files/b/tiger/62QMEQqZ3pjUds4DfuVtX_model.glb"
  },
  "thumbnail": {
    "file_size": 70958,
    "file_name": "preview.png",
    "content_type": "image/png",
    "url": "https://v3b.fal.media/files/b/koala/2NI_hEd7jXzS5rLQhnRga_preview.png"
  },
  "model_urls": {
    "fbx": {
      "file_size": 5574540,
      "file_name": "model.fbx",
      "content_type": "application/octet-stream",
      "url": "https://v3b.fal.media/files/b/koala/R7vPBgkecVvcnbNpRAy9x_model.fbx"
    },
    "usdz": {
      "file_size": 8631497,
      "file_name": "model.usdz",
      "content_type": "model/vnd.usdz+zip",
      "url": "https://v3b.fal.media/files/b/panda/fSGLGmtgzUjhepklN06Zw_model.usdz"
    },
    "glb": {
      "file_size": 7875308,
      "file_name": "model.glb",
      "content_type": "model/gltf-binary",
      "url": "https://v3b.fal.media/files/b/tiger/62QMEQqZ3pjUds4DfuVtX_model.glb"
    },
    "obj": {
      "file_size": 2761323,
      "file_name": "model.obj",
      "content_type": "text/plain",
      "url": "https://v3b.fal.media/files/b/koala/xmOnmSeePfuROe3pqHpf0_model.obj"
    }
  },
  "texture_urls": [
    {
      "base_color": {
        "file_size": 4464364,
        "file_name": "texture_0.png",
        "content_type": "image/png",
        "url": "https://v3b.fal.media/files/b/panda/OVrRor7IgeNK9w2i5-NDf_texture_0.png"
      }
    }
  ],
  "seed": 783032043
}
Other types
#
TextureFiles
#
base_color File
Base color texture

metallic File
Metallic texture (PBR)

normal File
Normal texture (PBR)

roughness File
Roughness texture (PBR)

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

ModelUrls
#
glb File
GLB format 3D model

fbx File
FBX format 3D model

obj File
OBJ format 3D model

usdz File
USDZ format 3D model


fal-ai/kling-video/v2.1/master/image-to-video

2.1 Master (Image to Video)
Kling 2.1 Master: The premium endpoint for Kling 2.1, designed for top-tier image-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Kling 2.1 Master Image to Video API.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/kling-video/v2.1/master/image-to-video", {
  input: {
    prompt: "Sunlight dapples through budding branches, illuminating a vibrant tapestry of greens and browns as a pair of robins meticulously weave twigs and mud into a cradle of life, their tiny forms a whirlwind of activity against a backdrop of blossoming spring.  The scene unfolds with a gentle, observational pace, allowing the viewer to fully appreciate the intricate details of nest construction, the soft textures of downy feathers contrasted against the rough bark of the branches, the delicate balance of strength and fragility in their creation.",
    image_url: "https://v3.fal.media/files/zebra/9Nrm22YyLojSTPJbZYNhh_image.webp"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/kling-video/v2.1/master/image-to-video", {
  input: {
    prompt: "Sunlight dapples through budding branches, illuminating a vibrant tapestry of greens and browns as a pair of robins meticulously weave twigs and mud into a cradle of life, their tiny forms a whirlwind of activity against a backdrop of blossoming spring.  The scene unfolds with a gentle, observational pace, allowing the viewer to fully appreciate the intricate details of nest construction, the soft textures of downy feathers contrasted against the rough bark of the branches, the delicate balance of strength and fragility in their creation.",
    image_url: "https://v3.fal.media/files/zebra/9Nrm22YyLojSTPJbZYNhh_image.webp"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/kling-video/v2.1/master/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/kling-video/v2.1/master/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5


{
  "prompt": "Sunlight dapples through budding branches, illuminating a vibrant tapestry of greens and browns as a pair of robins meticulously weave twigs and mud into a cradle of life, their tiny forms a whirlwind of activity against a backdrop of blossoming spring.  The scene unfolds with a gentle, observational pace, allowing the viewer to fully appreciate the intricate details of nest construction, the soft textures of downy feathers contrasted against the rough bark of the branches, the delicate balance of strength and fragility in their creation.",
  "image_url": "https://v3.fal.media/files/zebra/9Nrm22YyLojSTPJbZYNhh_image.webp",
  "duration": "5",
  "negative_prompt": "blur, distort, and low quality",
  "cfg_scale": 0.5
}
Output
#
video File
The generated video


{
  "video": {
    "url": "https://v3.fal.media/files/rabbit/YuUWKFq508zzWIiQ0i2vt_output.mp4"
  }
}
Other types
#
TextToVideoV21MasterRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

ProImageToVideoRequest
#
prompt string
image_url string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

tail_image_url string
URL of the image to be used for the end of the video

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

V1TextToVideoRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

camera_control CameraControlEnum
Camera control parameters

Possible enum values: down_back, forward_up, right_turn_forward, left_turn_forward

advanced_camera_control CameraControl
Advanced Camera control parameters

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

TextToVideoV25ProRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

ImageToVideoRequest
#
prompt string
image_url string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

LipsyncA2VRequest
#
video_url string
The URL of the video to generate the lip sync for. Supports .mp4/.mov, ≤100MB, 2–10s, 720p/1080p only, width/height 720–1920px.

audio_url string
The URL of the audio to generate the lip sync for. Minimum duration is 2s and maximum duration is 60s. Maximum file size is 5MB.

CameraControl
#
movement_type MovementTypeEnum
The type of camera movement

Possible enum values: horizontal, vertical, pan, tilt, roll, zoom

movement_value integer
The value of the camera movement

ImageToVideoV21StandardRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

TextToVideoRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

LipsyncT2VRequest
#
video_url string
The URL of the video to generate the lip sync for. Supports .mp4/.mov, ≤100MB, 2-60s, 720p/1080p only, width/height 720–1920px. If validation fails, an error is returned.

text string
Text content for lip-sync video generation. Max 120 characters.

voice_id VoiceIdEnum
Voice ID to use for speech synthesis

Possible enum values: genshin_vindi2, zhinen_xuesheng, AOT, ai_shatang, genshin_klee2, genshin_kirara, ai_kaiya, oversea_male1, ai_chenjiahao_712, girlfriend_4_speech02, chat1_female_new-3, chat_0407_5-1, cartoon-boy-07, uk_boy1, cartoon-girl-01, PeppaPig_platform, ai_huangzhong_712, ai_huangyaoshi_712, ai_laoguowang_712, chengshu_jiejie, you_pingjing, calm_story1, uk_man2, laopopo_speech02, heainainai_speech02, reader_en_m-v1, commercial_lady_en_f-v1, tiyuxi_xuedi, tiexin_nanyou, girlfriend_1_speech02, girlfriend_2_speech02, zhuxi_speech02, uk_oldman3, dongbeilaotie_speech02, chongqingxiaohuo_speech02, chuanmeizi_speech02, chaoshandashu_speech02, ai_taiwan_man2_speech02, xianzhanggui_speech02, tianjinjiejie_speech02, diyinnansang_DB_CN_M_04-v2, yizhipiannan-v1, guanxiaofang-v2, tianmeixuemei-v1, daopianyansang-v1, mengwa-v1

voice_language VoiceLanguageEnum
The voice language corresponding to the Voice ID Default value: "en"

Possible enum values: zh, en

voice_speed float
Speech rate for Text to Video generation Default value: 1

ImageToVideoV21ProRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

tail_image_url string
URL of the image to be used for the end of the video

DynamicMask
#
mask_url string
URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)

trajectories list<Trajectory>
List of trajectories

ImageToVideoV25ProRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

VideoEffectsRequest
#
input_image_urls list<string>
URL of images to be used for hug, kiss or heart_gesture video.

effect_scene EffectSceneEnum
The effect scene to use for the video generation

Possible enum values: hug, kiss, heart_gesture, squish, expansion, fuzzyfuzzy, bloombloom, dizzydizzy, jelly_press, jelly_slice, jelly_squish, jelly_jiggle, pixelpixel, yearbook, instant_film, anime_figure, rocketrocket

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

MultiImageToVideoRequest
#
prompt string
input_image_urls list<string>
List of image URLs to use for video generation. Supports up to 4 images.

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

V1ImageToVideoRequest
#
prompt string
The prompt for the video

image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

tail_image_url string
URL of the image to be used for the end of the video

static_mask_url string
URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)

dynamic_masks list<DynamicMask>
List of dynamic masks

TextToVideoV2MasterRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

Trajectory
#
x integer
X coordinate of the motion trajectory

y integer
Y coordinate of the motion trajectory

ImageToVideoV2MasterRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

fal-ai/kling-video/v2.1/master/text-to-video

2.1 Master (Text to Video)
Kling 2.1 Master: The premium endpoint for Kling 2.1, designed for top-tier text-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Kling 2.1 Master Text to Video API.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/kling-video/v2.1/master/text-to-video", {
  input: {
    prompt: "Warm, earthy tones bathe the scene as the potter's hands, rough and calloused, coax a shapeless lump of clay into a vessel of elegant curves, the slow, deliberate movements highlighted by the subtle shifting light; the clay's cool, damp texture contrasts sharply with the warmth of the potter's touch, creating a captivating interplay between material and maker."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/kling-video/v2.1/master/text-to-video", {
  input: {
    prompt: "Warm, earthy tones bathe the scene as the potter's hands, rough and calloused, coax a shapeless lump of clay into a vessel of elegant curves, the slow, deliberate movements highlighted by the subtle shifting light; the clay's cool, damp texture contrasts sharply with the warmth of the potter's touch, creating a captivating interplay between material and maker."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/kling-video/v2.1/master/text-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/kling-video/v2.1/master/text-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5


{
  "prompt": "Warm, earthy tones bathe the scene as the potter's hands, rough and calloused, coax a shapeless lump of clay into a vessel of elegant curves, the slow, deliberate movements highlighted by the subtle shifting light; the clay's cool, damp texture contrasts sharply with the warmth of the potter's touch, creating a captivating interplay between material and maker.",
  "duration": "5",
  "aspect_ratio": "16:9",
  "negative_prompt": "blur, distort, and low quality",
  "cfg_scale": 0.5
}
Output
#
video File
The generated video


{
  "video": {
    "url": "https://v3.fal.media/files/lion/0wTlhR7GCXFI-_BZXGy99_output.mp4"
  }
}
Other types
#
ProImageToVideoRequest
#
prompt string
image_url string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

tail_image_url string
URL of the image to be used for the end of the video

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

V1TextToVideoRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

camera_control CameraControlEnum
Camera control parameters

Possible enum values: down_back, forward_up, right_turn_forward, left_turn_forward

advanced_camera_control CameraControl
Advanced Camera control parameters

File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

TextToVideoV25ProRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

ImageToVideoRequest
#
prompt string
image_url string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

ImageToVideoV21MasterRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

LipsyncA2VRequest
#
video_url string
The URL of the video to generate the lip sync for. Supports .mp4/.mov, ≤100MB, 2–10s, 720p/1080p only, width/height 720–1920px.

audio_url string
The URL of the audio to generate the lip sync for. Minimum duration is 2s and maximum duration is 60s. Maximum file size is 5MB.

CameraControl
#
movement_type MovementTypeEnum
The type of camera movement

Possible enum values: horizontal, vertical, pan, tilt, roll, zoom

movement_value integer
The value of the camera movement

ImageToVideoV21StandardRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

TextToVideoRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

LipsyncT2VRequest
#
video_url string
The URL of the video to generate the lip sync for. Supports .mp4/.mov, ≤100MB, 2-60s, 720p/1080p only, width/height 720–1920px. If validation fails, an error is returned.

text string
Text content for lip-sync video generation. Max 120 characters.

voice_id VoiceIdEnum
Voice ID to use for speech synthesis

Possible enum values: genshin_vindi2, zhinen_xuesheng, AOT, ai_shatang, genshin_klee2, genshin_kirara, ai_kaiya, oversea_male1, ai_chenjiahao_712, girlfriend_4_speech02, chat1_female_new-3, chat_0407_5-1, cartoon-boy-07, uk_boy1, cartoon-girl-01, PeppaPig_platform, ai_huangzhong_712, ai_huangyaoshi_712, ai_laoguowang_712, chengshu_jiejie, you_pingjing, calm_story1, uk_man2, laopopo_speech02, heainainai_speech02, reader_en_m-v1, commercial_lady_en_f-v1, tiyuxi_xuedi, tiexin_nanyou, girlfriend_1_speech02, girlfriend_2_speech02, zhuxi_speech02, uk_oldman3, dongbeilaotie_speech02, chongqingxiaohuo_speech02, chuanmeizi_speech02, chaoshandashu_speech02, ai_taiwan_man2_speech02, xianzhanggui_speech02, tianjinjiejie_speech02, diyinnansang_DB_CN_M_04-v2, yizhipiannan-v1, guanxiaofang-v2, tianmeixuemei-v1, daopianyansang-v1, mengwa-v1

voice_language VoiceLanguageEnum
The voice language corresponding to the Voice ID Default value: "en"

Possible enum values: zh, en

voice_speed float
Speech rate for Text to Video generation Default value: 1

ImageToVideoV21ProRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

tail_image_url string
URL of the image to be used for the end of the video

DynamicMask
#
mask_url string
URL of the image for Dynamic Brush Application Area (Mask image created by users using the motion brush)

trajectories list<Trajectory>
List of trajectories

ImageToVideoV25ProRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

VideoEffectsRequest
#
input_image_urls list<string>
URL of images to be used for hug, kiss or heart_gesture video.

effect_scene EffectSceneEnum
The effect scene to use for the video generation

Possible enum values: hug, kiss, heart_gesture, squish, expansion, fuzzyfuzzy, bloombloom, dizzydizzy, jelly_press, jelly_slice, jelly_squish, jelly_jiggle, pixelpixel, yearbook, instant_film, anime_figure, rocketrocket

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

MultiImageToVideoRequest
#
prompt string
input_image_urls list<string>
List of image URLs to use for video generation. Supports up to 4 images.

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

V1ImageToVideoRequest
#
prompt string
The prompt for the video

image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

tail_image_url string
URL of the image to be used for the end of the video

static_mask_url string
URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)

dynamic_masks list<DynamicMask>
List of dynamic masks

TextToVideoV2MasterRequest
#
prompt string
duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

aspect_ratio AspectRatioEnum
The aspect ratio of the generated video frame Default value: "16:9"

Possible enum values: 16:9, 9:16, 1:1

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

Trajectory
#
x integer
X coordinate of the motion trajectory

y integer
Y coordinate of the motion trajectory

ImageToVideoV2MasterRequest
#
prompt string
image_url string
URL of the image to be used for the video

duration DurationEnum
The duration of the generated video in seconds Default value: "5"

Possible enum values: 5, 10

negative_prompt string
Default value: "blur, distort, and low quality"

cfg_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt. Default value: 0.5

fal-ai/flux-pro/kontext/max

Kontext [max] -- Editing
FLUX.1 Kontext [max] is a model with greatly improved prompt adherence and typography generation meet premium consistency for editing without compromise on speed.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
FLUX.1 Kontext [Max] -- Frontier image editing model.

Kontext Max is a more powerful version of Kontext that can handle more complex tasks.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/flux-pro/kontext/max", {
  input: {
    prompt: "Put a donut next to the flour.",
    image_url: "https://v3.fal.media/files/rabbit/rmgBxhwGYb2d3pl3x9sKf_output.png"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/flux-pro/kontext/max", {
  input: {
    prompt: "Put a donut next to the flour.",
    image_url: "https://v3.fal.media/files/rabbit/rmgBxhwGYb2d3pl3x9sKf_output.png"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/flux-pro/kontext/max", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/flux-pro/kontext/max", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The prompt to generate an image from.

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated image.

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21

image_url string
Image prompt for the omni model.


{
  "prompt": "Put a donut next to the flour.",
  "guidance_scale": 3.5,
  "num_images": 1,
  "output_format": "jpeg",
  "safety_tolerance": "2",
  "image_url": "https://v3.fal.media/files/rabbit/rmgBxhwGYb2d3pl3x9sKf_output.png"
}
Output
#
images list<fal__toolkit__image__image__Image>
The generated image files info.

timings Timings
seed integer
Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.

has_nsfw_concepts list<boolean>
Whether the generated images contain NSFW concepts.

prompt string
The prompt used for generating the image.


{
  "images": [
    {
      "height": 1024,
      "url": "https://fal.media/files/tiger/7dSJbIU_Ni-0Zp9eaLsvR_fe56916811d84ac69c6ffc0d32dca151.jpg",
      "width": 1024
    }
  ],
  "prompt": ""
}
Other types
#
registry__image__fast_sdxl__models__Image
#
url string
width integer
height integer
content_type string
Default value: "image/jpeg"

FluxProRedux
#
prompt string
The prompt to generate an image from. Default value: ""

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

FluxProV1Redux
#
prompt string
The prompt to generate an image from. Default value: ""

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

fal__toolkit__image__image__Image
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

width integer
The width of the image in pixels.

height integer
The height of the image in pixels.

FluxProUltraTextToImageInputRedux
#
prompt string
The prompt to generate an image from. Default value: ""

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

image_prompt_strength float
The strength of the image prompt, between 0 and 1. Default value: 0.1

aspect_ratio Enum | string
The aspect ratio of the generated image. Default value: 16:9

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21

raw boolean
Generate less processed, more natural-looking images.

ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512

FluxProTextToImageInputWithAR
#
prompt string
The prompt to generate an image from.

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated image. Default value: "1:1"

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21

fal-ai/flux-pro/kontext/max/multi

Kontext [max] -- Editing (experimental Multi Image)
Experimental version of FLUX.1 Kontext [max] with multi image handling capabilities
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Experimental version of FLUX.1 Kontext [Max] with multiple images.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/flux-pro/kontext/max/multi", {
  input: {
    prompt: "Put the little duckling on top of the woman's t-shirt.",
    image_urls: ["https://v3.fal.media/files/penguin/XoW0qavfF-ahg-jX4BMyL_image.webp", "https://v3.fal.media/files/tiger/bml6YA7DWJXOigadvxk75_image.webp"]
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/flux-pro/kontext/max/multi", {
  input: {
    prompt: "Put the little duckling on top of the woman's t-shirt.",
    image_urls: ["https://v3.fal.media/files/penguin/XoW0qavfF-ahg-jX4BMyL_image.webp", "https://v3.fal.media/files/tiger/bml6YA7DWJXOigadvxk75_image.webp"]
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/flux-pro/kontext/max/multi", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/flux-pro/kontext/max/multi", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The prompt to generate an image from.

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated image.

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21

image_urls list<string>
Image prompt for the omni model.


{
  "prompt": "Put the little duckling on top of the woman's t-shirt.",
  "guidance_scale": 3.5,
  "num_images": 1,
  "output_format": "jpeg",
  "safety_tolerance": "2",
  "image_urls": [
    "https://v3.fal.media/files/penguin/XoW0qavfF-ahg-jX4BMyL_image.webp",
    "https://v3.fal.media/files/tiger/bml6YA7DWJXOigadvxk75_image.webp"
  ]
}
Output
#
images list<registry__image__fast_sdxl__models__Image>
The generated image files info.

timings Timings
seed integer
Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.

has_nsfw_concepts list<boolean>
Whether the generated images contain NSFW concepts.

prompt string
The prompt used for generating the image.


{
  "images": [
    {
      "url": "",
      "content_type": "image/jpeg"
    }
  ],
  "prompt": ""
}
Other types
#
registry__image__fast_sdxl__models__Image
#
url string
width integer
height integer
content_type string
Default value: "image/jpeg"

FluxProRedux
#
prompt string
The prompt to generate an image from. Default value: ""

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

FluxProV1Redux
#
prompt string
The prompt to generate an image from. Default value: ""

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

fal__toolkit__image__image__Image
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

width integer
The width of the image in pixels.

height integer
The height of the image in pixels.

FluxProUltraTextToImageInputRedux
#
prompt string
The prompt to generate an image from. Default value: ""

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

image_prompt_strength float
The strength of the image prompt, between 0 and 1. Default value: 0.1

aspect_ratio Enum | string
The aspect ratio of the generated image. Default value: 16:9

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21

raw boolean
Generate less processed, more natural-looking images.

ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512

FluxProTextToImageInputWithAR
#
prompt string
The prompt to generate an image from.

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated image. Default value: "1:1"

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21

fal-ai/flux-pro/kontext/max/text-to-image

Kontext [max] -- Text to Image
FLUX.1 Kontext [max] text-to-image is a new premium model brings maximum performance across all aspects – greatly improved prompt adherence.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
FLUX.1 Kontext [Max] -- Frontier image generation model.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/flux-pro/kontext/max/text-to-image", {
  input: {
    prompt: "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/flux-pro/kontext/max/text-to-image", {
  input: {
    prompt: "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/flux-pro/kontext/max/text-to-image", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/flux-pro/kontext/max/text-to-image", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The prompt to generate an image from.

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated image. Default value: "1:1"

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21


{
  "prompt": "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture.",
  "guidance_scale": 3.5,
  "num_images": 1,
  "output_format": "jpeg",
  "safety_tolerance": "2",
  "aspect_ratio": "1:1"
}
Output
#
images list<registry__image__fast_sdxl__models__Image>
The generated image files info.

timings Timings
seed integer
Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.

has_nsfw_concepts list<boolean>
Whether the generated images contain NSFW concepts.

prompt string
The prompt used for generating the image.


{
  "images": [
    {
      "url": "",
      "content_type": "image/jpeg"
    }
  ],
  "prompt": ""
}
Other types
#
registry__image__fast_sdxl__models__Image
#
url string
width integer
height integer
content_type string
Default value: "image/jpeg"

FluxProRedux
#
prompt string
The prompt to generate an image from. Default value: ""

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

FluxProV1Redux
#
prompt string
The prompt to generate an image from. Default value: ""

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

fal__toolkit__image__image__Image
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

width integer
The width of the image in pixels.

height integer
The height of the image in pixels.

FluxProUltraTextToImageInputRedux
#
prompt string
The prompt to generate an image from. Default value: ""

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

image_prompt_strength float
The strength of the image prompt, between 0 and 1. Default value: 0.1

aspect_ratio Enum | string
The aspect ratio of the generated image. Default value: 16:9

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21

raw boolean
Generate less processed, more natural-looking images.

ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512

fal-ai/flux-pro/kontext/multi

Kontext [pro] -- Editing (experimental Multi Image)
Experimental version of FLUX.1 Kontext [pro] with multi image handling capabilities
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Experimental version of FLUX.1 Kontext [pro] with multiple images.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/flux-pro/kontext/multi", {
  input: {
    prompt: "Put the little duckling on top of the woman's t-shirt.",
    image_urls: ["https://v3.fal.media/files/penguin/XoW0qavfF-ahg-jX4BMyL_image.webp", "https://v3.fal.media/files/tiger/bml6YA7DWJXOigadvxk75_image.webp"]
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/flux-pro/kontext/multi", {
  input: {
    prompt: "Put the little duckling on top of the woman's t-shirt.",
    image_urls: ["https://v3.fal.media/files/penguin/XoW0qavfF-ahg-jX4BMyL_image.webp", "https://v3.fal.media/files/tiger/bml6YA7DWJXOigadvxk75_image.webp"]
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/flux-pro/kontext/multi", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/flux-pro/kontext/multi", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The prompt to generate an image from.

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated image.

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21

image_urls list<string>
Image prompt for the omni model.


{
  "prompt": "Put the little duckling on top of the woman's t-shirt.",
  "guidance_scale": 3.5,
  "num_images": 1,
  "output_format": "jpeg",
  "safety_tolerance": "2",
  "image_urls": [
    "https://v3.fal.media/files/penguin/XoW0qavfF-ahg-jX4BMyL_image.webp",
    "https://v3.fal.media/files/tiger/bml6YA7DWJXOigadvxk75_image.webp"
  ]
}
Output
#
images list<registry__image__fast_sdxl__models__Image>
The generated image files info.

timings Timings
seed integer
Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.

has_nsfw_concepts list<boolean>
Whether the generated images contain NSFW concepts.

prompt string
The prompt used for generating the image.


{
  "images": [
    {
      "url": "",
      "content_type": "image/jpeg"
    }
  ],
  "prompt": ""
}
Other types
#
registry__image__fast_sdxl__models__Image
#
url string
width integer
height integer
content_type string
Default value: "image/jpeg"

FluxProRedux
#
prompt string
The prompt to generate an image from. Default value: ""

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

FluxProV1Redux
#
prompt string
The prompt to generate an image from. Default value: ""

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

fal__toolkit__image__image__Image
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

width integer
The width of the image in pixels.

height integer
The height of the image in pixels.

FluxProUltraTextToImageInputRedux
#
prompt string
The prompt to generate an image from. Default value: ""

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

image_prompt_strength float
The strength of the image prompt, between 0 and 1. Default value: 0.1

aspect_ratio Enum | string
The aspect ratio of the generated image. Default value: 16:9

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21

raw boolean
Generate less processed, more natural-looking images.

ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512

FluxProTextToImageInputWithAR
#
prompt string
The prompt to generate an image from.

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated image. Default value: "1:1"

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21

fal-ai/flux-pro/kontext/text-to-image

Kontext [pro] -- Text to Image
The FLUX.1 Kontext [pro] text-to-image delivers state-of-the-art image generation results with unprecedented prompt following, photorealistic rendering, and flawless typography.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
FLUX.1 Kontext [pro] -- Frontier image generation model.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/flux-pro/kontext/text-to-image", {
  input: {
    prompt: "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/flux-pro/kontext/text-to-image", {
  input: {
    prompt: "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/flux-pro/kontext/text-to-image", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/flux-pro/kontext/text-to-image", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
The prompt to generate an image from.

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

aspect_ratio AspectRatioEnum
The aspect ratio of the generated image. Default value: "1:1"

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21


{
  "prompt": "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture.",
  "guidance_scale": 3.5,
  "num_images": 1,
  "output_format": "jpeg",
  "safety_tolerance": "2",
  "aspect_ratio": "1:1"
}
Output
#
images list<registry__image__fast_sdxl__models__Image>
The generated image files info.

timings Timings
seed integer
Seed of the generated Image. It will be the same value of the one passed in the input or the randomly generated that was used in case none was passed.

has_nsfw_concepts list<boolean>
Whether the generated images contain NSFW concepts.

prompt string
The prompt used for generating the image.


{
  "images": [
    {
      "url": "",
      "content_type": "image/jpeg"
    }
  ],
  "prompt": ""
}
Other types
#
registry__image__fast_sdxl__models__Image
#
url string
width integer
height integer
content_type string
Default value: "image/jpeg"

FluxProRedux
#
prompt string
The prompt to generate an image from. Default value: ""

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

FluxProV1Redux
#
prompt string
The prompt to generate an image from. Default value: ""

image_size ImageSize | Enum
The size of the generated image. Default value: landscape_4_3

Possible enum values: square_hd, square, portrait_4_3, portrait_16_9, landscape_4_3, landscape_16_9

Note: For custom image sizes, you can pass the width and height as an object:


"image_size": {
  "width": 1280,
  "height": 720
}
num_inference_steps integer
The number of inference steps to perform. Default value: 28

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

guidance_scale float
The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you. Default value: 3.5

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

fal__toolkit__image__image__Image
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

width integer
The width of the image in pixels.

height integer
The height of the image in pixels.

FluxProUltraTextToImageInputRedux
#
prompt string
The prompt to generate an image from. Default value: ""

seed integer
The same seed and the same prompt given to the same version of the model will output the same image every time.

sync_mode boolean
If True, the media will be returned as a data URI and the output data won't be available in the request history.

num_images integer
The number of images to generate. Default value: 1

enable_safety_checker boolean
If set to true, the safety checker will be enabled. Default value: true

output_format OutputFormatEnum
The format of the generated image. Default value: "jpeg"

Possible enum values: jpeg, png

safety_tolerance SafetyToleranceEnum
The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive. Default value: "2"

Possible enum values: 1, 2, 3, 4, 5, 6

Note: This property is only available through API calls.

enhance_prompt boolean
Whether to enhance the prompt for better results.

image_url string
The image URL to generate an image from. Needs to match the dimensions of the mask.

image_prompt_strength float
The strength of the image prompt, between 0 and 1. Default value: 0.1

aspect_ratio Enum | string
The aspect ratio of the generated image. Default value: 16:9

Possible enum values: 21:9, 16:9, 4:3, 3:2, 1:1, 2:3, 3:4, 9:16, 9:21

raw boolean
Generate less processed, more natural-looking images.

ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512

decart/lucy-5b/image-to-video

Lucy-5B is a model that can create 5-second I2V videos in under 5 seconds, achieving >1x RTF end-to-end
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Generate a video from an input image and text prompt using AI video generation models.

This endpoint accepts a base64-encoded image and a text prompt, then returns an MP4 video file with H.264 encoding.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("decart/lucy-5b/image-to-video", {
  input: {
    prompt: "Viking warrior, powerful build, battle-ready pose, fierce expression beneath war paint, fur-lined armor with battle axe, longship on stormy seas, dramatic storm lighting, action combat stance, long braided blonde hair with beaded beard, weathered face with ritual scars, northern warrior spirit",
    image_url: "https://storage.googleapis.com/falserverless/model_tests/lucy-5b/lucy-5b-viking-image.jpg"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("decart/lucy-5b/image-to-video", {
  input: {
    prompt: "Viking warrior, powerful build, battle-ready pose, fierce expression beneath war paint, fur-lined armor with battle axe, longship on stormy seas, dramatic storm lighting, action combat stance, long braided blonde hair with beaded beard, weathered face with ritual scars, northern warrior spirit",
    image_url: "https://storage.googleapis.com/falserverless/model_tests/lucy-5b/lucy-5b-viking-image.jpg"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("decart/lucy-5b/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("decart/lucy-5b/image-to-video", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
prompt string
Text description of the desired video content

image_url string
URL of the image to use as the first frame

aspect_ratio AspectRatioEnum
Aspect ratio of the generated video. Default value: "16:9"

Possible enum values: 9:16, 16:9

sync_mode boolean
If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN. Default value: true


{
  "prompt": "Viking warrior, powerful build, battle-ready pose, fierce expression beneath war paint, fur-lined armor with battle axe, longship on stormy seas, dramatic storm lighting, action combat stance, long braided blonde hair with beaded beard, weathered face with ritual scars, northern warrior spirit",
  "image_url": "https://storage.googleapis.com/falserverless/model_tests/lucy-5b/lucy-5b-viking-image.jpg",
  "aspect_ratio": "16:9",
  "sync_mode": true
}
Output
#
video File
The generated video


{
  "video": {
    "url": "https://storage.googleapis.com/falserverless/model_tests/lucy-5b/lucy-5b-viking-image-output.mp4"
  }
}
Other types
#
File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string

fal-ai/wan-trainer/t2v-14b

T2V 14B
Train custom LoRAs for Wan-2.1 T2V 14B
Training
Commercial use
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Runs training on the T2V 14B model.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/wan-trainer/t2v-14b", {
  input: {
    training_data_url: ""
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/wan-trainer/t2v-14b", {
  input: {
    training_data_url: ""
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/wan-trainer/t2v-14b", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/wan-trainer/t2v-14b", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
training_data_url string
URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.

In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to.

number_of_steps integer
The number of steps to train for. Default value: 400

learning_rate float
The rate at which the model learns. Higher values can lead to faster training, but over-fitting. Default value: 0.0002

trigger_phrase string
The phrase that will trigger the model to generate an image. Default value: ""

auto_scale_input boolean
If true, the input will be automatically scale the video to 81 frames at 16fps.


{
  "training_data_url": "",
  "number_of_steps": 400,
  "learning_rate": 0.0002,
  "auto_scale_input": true
}
Output
#
lora_file File
URL to the trained LoRA weights.

config_file File
Configuration used for setting up the inference endpoints.


{
  "lora_file": {
    "url": "",
    "content_type": "image/png",
    "file_name": "z9RV14K95DvU.png",
    "file_size": 4404019
  },
  "config_file": {
    "url": "",
    "content_type": "image/png",
    "file_name": "z9RV14K95DvU.png",
    "file_size": 4404019
  }
}
Other types
#
File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

fal-ai/wan-trainer/t2v

T2V 1.3B
Train custom LoRAs for Wan-2.1 T2V 1.3B
Training
Commercial use
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Runs training on the T2V 1.3B model.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/wan-trainer/t2v", {
  input: {
    training_data_url: ""
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/wan-trainer/t2v", {
  input: {
    training_data_url: ""
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/wan-trainer/t2v", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/wan-trainer/t2v", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
training_data_url string
URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.

In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to.

number_of_steps integer
The number of steps to train for. Default value: 400

learning_rate float
The rate at which the model learns. Higher values can lead to faster training, but over-fitting. Default value: 0.0002

trigger_phrase string
The phrase that will trigger the model to generate an image. Default value: ""

auto_scale_input boolean
If true, the input will be automatically scale the video to 81 frames at 16fps.


{
  "training_data_url": "",
  "number_of_steps": 400,
  "learning_rate": 0.0002,
  "auto_scale_input": true
}
Output
#
lora_file File
URL to the trained LoRA weights.

config_file File
Configuration used for setting up the inference endpoints.


{
  "lora_file": {
    "url": "",
    "content_type": "image/png",
    "file_name": "z9RV14K95DvU.png",
    "file_size": 4404019
  },
  "config_file": {
    "url": "",
    "content_type": "image/png",
    "file_name": "z9RV14K95DvU.png",
    "file_size": 4404019
  }
}
Other types
#
File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

fal-ai/wan-trainer/i2v-720p

I2V 14B 720P
Train custom LoRAs for Wan-2.1 I2V 720P
Training
Commercial use
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Runs training on the I2V 14B 720P model.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/wan-trainer/i2v-720p", {
  input: {
    training_data_url: ""
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/wan-trainer/i2v-720p", {
  input: {
    training_data_url: ""
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/wan-trainer/i2v-720p", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/wan-trainer/i2v-720p", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
training_data_url string
URL to zip archive with images of a consistent style. Try to use at least 10 images and/or videos, although more is better.

In addition to images the archive can contain text files with captions. Each text file should have the same name as the image/video file it corresponds to.

number_of_steps integer
The number of steps to train for. Default value: 400

learning_rate float
The rate at which the model learns. Higher values can lead to faster training, but over-fitting. Default value: 0.0002

trigger_phrase string
The phrase that will trigger the model to generate an image. Default value: ""

auto_scale_input boolean
If true, the input will be automatically scale the video to 81 frames at 16fps.


{
  "training_data_url": "",
  "number_of_steps": 400,
  "learning_rate": 0.0002,
  "auto_scale_input": true
}
Output
#
lora_file File
URL to the trained LoRA weights.

config_file File
Configuration used for setting up the inference endpoints.


{
  "lora_file": {
    "url": "",
    "content_type": "image/png",
    "file_name": "z9RV14K95DvU.png",
    "file_size": 4404019
  },
  "config_file": {
    "url": "",
    "content_type": "image/png",
    "file_name": "z9RV14K95DvU.png",
    "file_size": 4404019
  }
}
Other types
#
File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

fal-ai/bytedance/omnihuman

OmniHuman generates video using an image of a human figure paired with an audio file. It produces vivid, high-quality videos where the character’s emotions and movements maintain a strong correlation with the audio.
Inference
Commercial use
Partner
Schema
LLMs

Table of contents

JavaScript / Node.js
1. Calling the API
Install the client
Setup your API Key
Submit a request
Streaming
2. Authentication
API Key
3. Queue
Submit a request
Fetch request status
Get the result
4. Files
Data URI (base64)
Hosted files (URL)
Uploading files
5. Schema
Input
Output
Other
About
Generate incredibly accurate videos of human beings speaking a dialogue using Bytednce's OmniHuman model.

This endpoint allows you to provide an image of a human along with an audio file to generate a video. The model will animate the image based on the audio.

1. Calling the API
#
Install the client
#
The client provides a convenient way to interact with the model API.

npmyarnpnpmbun

npm install --save @fal-ai/client
Migrate to @fal-ai/client
The @fal-ai/serverless-client package has been deprecated in favor of @fal-ai/client. Please check the migration guide for more information.

Setup your API Key
#
Set FAL_KEY as an environment variable in your runtime.


export FAL_KEY="YOUR_API_KEY"
Submit a request
#
The client API handles the API submit protocol. It will handle the request status updates and return the result when the request is completed.


import { fal } from "@fal-ai/client";

const result = await fal.subscribe("fal-ai/bytedance/omnihuman", {
  input: {
    image_url: "https://storage.googleapis.com/falserverless/example_inputs/omnihuman.png",
    audio_url: "https://storage.googleapis.com/falserverless/example_inputs/omnihuman_audio.mp3"
  },
  logs: true,
  onQueueUpdate: (update) => {
    if (update.status === "IN_PROGRESS") {
      update.logs.map((log) => log.message).forEach(console.log);
    }
  },
});
console.log(result.data);
console.log(result.requestId);
2. Authentication
#
The API uses an API Key for authentication. It is recommended you set the FAL_KEY environment variable in your runtime when possible.

API Key
#
In case your app is running in an environment where you cannot set environment variables, you can set the API Key manually as a client configuration.

import { fal } from "@fal-ai/client";

fal.config({
  credentials: "YOUR_FAL_KEY"
});
Protect your API Key
When running code on the client-side (e.g. in a browser, mobile app or GUI applications), make sure to not expose your FAL_KEY. Instead, use a server-side proxy to make requests to the API. For more information, check out our server-side integration guide.

3. Queue
#
Long-running requests
For long-running requests, such as training jobs or models with slower inference times, it is recommended to check the Queue status and rely on Webhooks instead of blocking while waiting for the result.

Submit a request
#
The client API provides a convenient way to submit requests to the model.


import { fal } from "@fal-ai/client";

const { request_id } = await fal.queue.submit("fal-ai/bytedance/omnihuman", {
  input: {
    image_url: "https://storage.googleapis.com/falserverless/example_inputs/omnihuman.png",
    audio_url: "https://storage.googleapis.com/falserverless/example_inputs/omnihuman_audio.mp3"
  },
  webhookUrl: "https://optional.webhook.url/for/results",
});
Fetch request status
#
You can fetch the status of a request to check if it is completed or still in progress.


import { fal } from "@fal-ai/client";

const status = await fal.queue.status("fal-ai/bytedance/omnihuman", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b",
  logs: true,
});
Get the result
#
Once the request is completed, you can fetch the result. See the Output Schema for the expected result format.


import { fal } from "@fal-ai/client";

const result = await fal.queue.result("fal-ai/bytedance/omnihuman", {
  requestId: "764cabcf-b745-4b3e-ae38-1200304cf45b"
});
console.log(result.data);
console.log(result.requestId);
4. Files
#
Some attributes in the API accept file URLs as input. Whenever that's the case you can pass your own URL or a Base64 data URI.

Data URI (base64)
#
You can pass a Base64 data URI as a file input. The API will handle the file decoding for you. Keep in mind that for large files, this alternative although convenient can impact the request performance.

Hosted files (URL)
#
You can also pass your own URLs as long as they are publicly accessible. Be aware that some hosts might block cross-site requests, rate-limit, or consider the request as a bot.

Uploading files
#
We provide a convenient file storage that allows you to upload files and use them in your requests. You can upload files using the client API and use the returned URL in your requests.


import { fal } from "@fal-ai/client";

const file = new File(["Hello, World!"], "hello.txt", { type: "text/plain" });
const url = await fal.storage.upload(file);
Auto uploads
The client will auto-upload the file for you if you pass a binary object (e.g. File, Data).

Read more about file handling in our file upload guide.

5. Schema
#
Input
#
image_url string
The URL of the image used to generate the video

audio_url string
The URL of the audio file to generate the video. Audio must be under 30s long.


{
  "image_url": "https://storage.googleapis.com/falserverless/example_inputs/omnihuman.png",
  "audio_url": "https://storage.googleapis.com/falserverless/example_inputs/omnihuman_audio.mp3"
}
Output
#
video File
Generated video file

duration float
Duration of audio input/video output as used for billing.


{
  "video": {
    "url": "https://storage.googleapis.com/falserverless/example_outputs/omnihuman_output.mp4"
  }
}
Other types
#
File
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

Image
#
url string
The URL where the file can be downloaded from.

content_type string
The mime type of the file.

file_name string
The name of the file. It will be auto-generated if not provided.

file_size integer
The size of the file in bytes.

file_data string
File data

width integer
The width of the image in pixels.

height integer
The height of the image in pixels.

ImageSize
#
width integer
The width of the generated image. Default value: 512

height integer
The height of the generated image. Default value: 512