# AI Model Endpoints Catalog

> **Last Updated**: 2025-01-14 (Session 3 - Lipsync Models Added)
> 
> **Progress**: 54/100+ models configured (54%)
> **UI**: Color-coded modal selector with category cards ✨

## Status Legend
- ✅ **Already Configured** - Model is currently in the dropdown
- 🆕 **New Model** - Needs to be added
- 🔄 **Update Available** - Newer version available
- ⚙️ **In Progress** - Currently being configured
- ✔️ **Recently Added** - Added in last update session

## Implementation Workflow
1. Select models to implement from a category
2. Add models to dropdown with proper configuration
3. Test the integration
4. Update this markdown with ✔️ status
5. Move to next batch

---

## 📸 Text-to-Image Models (23 Configured)

### ✅ Already Configured
1. `fal-ai/reve/text-to-image` - Reve Text-to-Image (strong aesthetic quality and accurate text rendering) ✔️
2. `fal-ai/reve/edit` - Reve Edit (transform existing images via text prompts) ✔️
3. `fal-ai/reve/remix` - Reve Remix (combine multiple reference images) ✔️
4. `fal-ai/wan-25-preview/text-to-image` - Wan 2.5 Text-to-Image (high quality) ✔️
5. `fal-ai/imagen4/preview` - Google Imagen 4 ✔️
6. `fal-ai/flux-pro/v1.1-ultra` - Flux Pro Ultra
7. `fal-ai/recraft/v3/text-to-image` - Recraft V3 ✔️
8. `fal-ai/hidream-i1-full` - HiDream-I1 ✔️
9. `fal-ai/flux-krea-lora/stream` - Flux Krea LoRA Stream ✔️
10. `fal-ai/qwen-image-edit/image-to-image` - Qwen Image Edit (superior text editing) ✔️
11. `fal-ai/wan-25-preview/image-to-image` - Wan 2.5 Image-to-Image (multi-ref fusion) ✔️
12. `fal-ai/nano-banana/edit` - Nano Banana Edit
13. `fal-ai/bytedance/seedream/v4/edit` - Seedream 4.0 Edit
14. `fal-ai/dreamomni2/edit` - DreamOmni2 Edit ✔️
15. `fal-ai/luma-photon/flash/reframe` - Luma Photon Flash Reframe ✔️
16. `fal-ai/flux-kontext-lora` - Flux Kontext LoRA ✔️
17. `fal-ai/flux-kontext-lora/text-to-image` - Flux Kontext LoRA T2I ✔️
18. `fal-ai/flux-kontext-lora/inpaint` - Flux Kontext Inpaint ✔️
19. `fal-ai/flux-pro/kontext/max/text-to-image` - Flux Pro Kontext Max T2I ✔️
20. `fal-ai/flux-pro/kontext/text-to-image` - Flux Pro Kontext T2I ✔️
21. `fal-ai/flux-pro/kontext/max` - Flux Pro Kontext Max ✔️
22. `fal-ai/flux-pro/kontext/max/multi` - Flux Pro Kontext Max Multi ✔️
23. `fal-ai/flux-pro/kontext/multi` - Flux Pro Kontext Multi ✔️

### 🆕 New Models to Add
- `fal-ai/luma-photon` - Luma Photon (creative, personalizable)
- `fal-ai/gemini-25-flash-image` - Gemini 2.5 Flash
- `fal-ai/stable-diffusion-v35-large` - Stable Diffusion 3.5 Large
- `fal-ai/qwen-image` - Qwen Image (complex text rendering)

---

## 🎬 Text-to-Video Models (16 Configured)

### ✅ Already Configured
1. `fal-ai/wan-alpha` - Wan Alpha (transparent backgrounds) ✔️
2. `fal-ai/wan-25-preview/text-to-video` - Wan 2.5 Text-to-Video (480p-1080p, 5-10s) ✔️
3. `fal-ai/veo3.1` - Veo 3.1 by Google (with sound, 720p/1080p, 4-8s) ✔️
4. `fal-ai/veo3.1/fast` - Veo 3.1 Fast (faster & cost effective) ✔️
5. `fal-ai/sora-2/text-to-video` - Sora 2 T2V ✔️
6. `fal-ai/sora-2/text-to-video/pro` - Sora 2 Pro T2V ✔️
7. `fal-ai/kandinsky5/text-to-video` - Kandinsky 5.0 ✔️
8. `fal-ai/kandinsky5/text-to-video/distill` - Kandinsky 5.0 Distilled ✔️
9. `fal-ai/ovi` - Ovi (Audio-Video) ✔️
10. `fal-ai/luma-dream-machine` - Luma Dream Machine v1.5 ✔️
11. `fal-ai/kling-video/v2.5-turbo/pro/text-to-video` - Kling 2.5 Turbo Pro ✔️
12. `fal-ai/kling-video/v2.1/master/text-to-video` - Kling 2.1 Master T2V ✔️
13. `fal-ai/veo3.1/reference-to-video` - Veo 3.1 Reference-to-Video (multiple images) ✔️
14. `fal-ai/wan-trainer/t2v-14b` - Wan Trainer T2V 14B ✔️
15. `fal-ai/wan-trainer/t2v` - Wan Trainer T2V ✔️
16. `fal-ai/bytedance/omnihuman` - OmniHuman (Avatar) ✔️

### 🆕 New Models to Add
- `fal-ai/veo3` - Veo 3 by Google (with sound)
- `fal-ai/hunyuan-video` - Hunyuan Video (open, high quality)

---

## 🖼️ Image-to-Video Models (25 Configured)

### ✅ Already Configured
1. `fal-ai/wan-25-preview/image-to-video` - Wan 2.5 Image-to-Video (480p-1080p, 5-10s, audio) ✔️
2. `fal-ai/veo3.1/image-to-video` - Veo 3.1 I2V (720p/1080p, 8s) ✔️
3. `fal-ai/veo3.1/fast/image-to-video` - Veo 3.1 Fast I2V (faster & cost effective) ✔️
4. `fal-ai/veo3.1/first-last-frame-to-video` - Veo 3.1 First/Last Frame (animate between frames) ✔️
5. `fal-ai/veo3.1/fast/first-last-frame-to-video` - Veo 3.1 Fast First/Last Frame ✔️
6. `fal-ai/sora-2/image-to-video` - Sora 2 I2V
7. `fal-ai/sora-2/image-to-video/pro` - Sora 2 Pro I2V
8. `fal-ai/veo3/image-to-video` - Veo 3 I2V
8. `fal-ai/kling-video/v2.1/master/image-to-video` - Kling v2.1 Master I2V
9. `fal-ai/kling-video/v2.5-turbo/pro/image-to-video` - Kling V2.5 Turbo Pro I2V
10. `fal-ai/minimax/hailuo-02/standard/image-to-video` - Minimax Hailuo 02 I2V
11. `fal-ai/hunyuan-video` - Hunyuan Video I2V
12. `fal-ai/wan/v2.2-a14b/image-to-video` - Wan v2.2-A14B I2V
13. `fal-ai/ovi/image-to-video` - Ovi I2V (with audio)
14. `fal-ai/luma-dream-machine/ray-2/image-to-video` - Luma Ray 2 I2V
15. `fal-ai/wan-25-preview/image-to-video` - Wan 2.5 Preview I2V
16. `fal-ai/luma-dream-machine/image-to-video` - Luma Dream Machine I2V ✔️
17. `fal-ai/luma-dream-machine/ray-2` - Luma Ray 2 ✔️
18. `fal-ai/luma-dream-machine/ray-2-flash` - Luma Ray 2 Flash ✔️
19. `fal-ai/luma-dream-machine/ray-2-flash/image-to-video` - Luma Ray 2 Flash I2V ✔️
20. `fal-ai/pixverse/v5/image-to-video` - PixVerse V5 I2V ✔️
21. `fal-ai/ltxv-13b-098-distilled/image-to-video` - LTX Video 0.9.8 13B ✔️
22. `decart/lucy-14b/image-to-video` - Lucy-14B (lightning fast) ✔️
23. `fal-ai/wan/v2.2-a14b/image-to-video/lora` - Wan 2.2 I2V LoRA ✔️
24. `fal-ai/bytedance/omnihuman` - OmniHuman (Image+Audio→Video) ✔️

### 🆕 New Models to Add
- `fal-ai/kling-video/v2.1/pro/image-to-video` - Kling 2.1 Pro I2V
- `fal-ai/ltx-video-13b-distilled/image-to-video` - LTX Video 0.9.7 13B Distilled

### 📋 Model Configuration Notes

**Veo 3.1** (`fal-ai/veo3.1`):
- **Category**: Text-to-Video
- **Input**: 
  - `prompt` (required) - text description
  - `aspect_ratio` (9:16/16:9/1:1, default: 16:9)
  - `duration` (4s/6s/8s, default: 8s)
  - `resolution` (720p/1080p, default: 720p)
  - `negative_prompt` (optional)
  - `enhance_prompt` (boolean, default: true)
  - `auto_fix` (boolean, default: true)
  - `generate_audio` (boolean, default: true - 33% less credits if false)
  - `seed` (optional)
- **Output**: `video` (File)
- **Use Case**: State-of-the-art text-to-video with audio generation
- **Status**: ✔️ Configured

**Veo 3.1 Fast** (`fal-ai/veo3.1/fast`):
- **Category**: Text-to-Video (Fast)
- **Input**: Same as Veo 3.1
- **Output**: `video` (File)
- **Use Case**: Faster and more cost-effective version of Veo 3.1
- **Status**: ✔️ Configured

**Veo 3.1 Image-to-Video** (`fal-ai/veo3.1/image-to-video`):
- **Category**: Image-to-Video
- **Input**: 
  - `prompt` (required)
  - `image_url` (required) - input image to animate
  - `aspect_ratio` (auto/9:16/16:9/1:1, default: auto)
  - `duration` (8s only)
  - `resolution` (720p/1080p, default: 720p)
  - `generate_audio` (boolean, default: true)
- **Output**: `video` (File)
- **Use Case**: Animate still images with Veo 3.1
- **Status**: ✔️ Configured

**Veo 3.1 Fast Image-to-Video** (`fal-ai/veo3.1/fast/image-to-video`):
- **Category**: Image-to-Video (Fast)
- **Input**: Same as Veo 3.1 I2V
- **Output**: `video` (File)
- **Use Case**: Faster image animation
- **Status**: ✔️ Configured

**Veo 3.1 First/Last Frame** (`fal-ai/veo3.1/first-last-frame-to-video`):
- **Category**: Image-to-Video
- **Input**: 
  - `first_frame_url` (required) - URL of first frame
  - `last_frame_url` (required) - URL of last frame
  - `prompt` (required) - how to animate between frames
  - `duration` (8s only)
  - `aspect_ratio` (auto/9:16/16:9/1:1, default: auto)
  - `resolution` (720p/1080p, default: 720p)
  - `generate_audio` (boolean, default: true)
- **Output**: `video` (File)
- **Use Case**: Animate between two keyframes
- **Status**: ✔️ Configured

**Veo 3.1 Fast First/Last Frame** (`fal-ai/veo3.1/fast/first-last-frame-to-video`):
- **Category**: Image-to-Video (Fast)
- **Input**: Same as Veo 3.1 First/Last Frame
- **Output**: `video` (File)
- **Use Case**: Faster keyframe animation
- **Status**: ✔️ Configured

**Veo 3.1 Reference-to-Video** (`fal-ai/veo3.1/reference-to-video`):
- **Category**: Text-to-Video (Multiple Images)
- **Input**: 
  - `image_urls` (required) - array of reference image URLs
  - `prompt` (required)
  - `duration` (8s only)
  - `resolution` (720p/1080p, default: 720p)
  - `generate_audio` (boolean, default: true)
- **Output**: `video` (File)
- **Use Case**: Generate videos with consistent subjects from multiple reference images
- **Status**: ✔️ Configured

**Sora 2 Image-to-Video** (`fal-ai/sora-2/image-to-video`):
- **Category**: Image-to-Video
- **Input**: 
  - `prompt` (required) - text description
  - `image_url` (required) - first frame image
  - `resolution` (auto/720p, default: auto)
  - `aspect_ratio` (auto/9:16/16:9, default: auto)
  - `duration` (4/8/12 seconds, integer, default: 4)
  - `api_key` (optional) - OpenAI API key (no FAL billing if provided)
- **Output**: `video` (VideoFile), `video_id` (string)
- **Use Case**: Animate images with OpenAI's Sora 2
- **Status**: ✔️ Configured

**Sora 2 Pro Image-to-Video** (`fal-ai/sora-2/image-to-video/pro`):
- **Category**: Image-to-Video (Pro)
- **Input**: 
  - `prompt` (required)
  - `image_url` (required)
  - `resolution` (auto/720p/1080p, default: auto)
  - `aspect_ratio` (auto/9:16/16:9, default: auto)
  - `duration` (4/8/12 seconds, integer, default: 4)
  - `api_key` (optional)
- **Output**: `video` (VideoFile), `video_id` (string)
- **Use Case**: Higher quality image animation with 1080p support
- **Status**: ✔️ Configured

**Sora 2 Text-to-Video** (`fal-ai/sora-2/text-to-video`):
- **Category**: Text-to-Video
- **Input**: 
  - `prompt` (required)
  - `resolution` (720p only)
  - `aspect_ratio` (9:16/16:9, default: 16:9)
  - `duration` (4/8/12 seconds, integer, default: 4)
  - `api_key` (optional)
- **Output**: `video` (VideoFile), `video_id` (string)
- **Use Case**: Generate videos from text with OpenAI's Sora 2
- **Status**: ✔️ Configured

**Sora 2 Pro Text-to-Video** (`fal-ai/sora-2/text-to-video/pro`):
- **Category**: Text-to-Video (Pro)
- **Input**: 
  - `prompt` (required)
  - `resolution` (720p/1080p, default: 1080p)
  - `aspect_ratio` (9:16/16:9, default: 16:9)
  - `duration` (4/8/12 seconds, integer, default: 4)
  - `api_key` (optional)
- **Output**: `video` (VideoFile), `video_id` (string)
- **Use Case**: Higher quality text-to-video with 1080p support
- **Status**: ✔️ Configured

**Sora 2 Video Remix** (`fal-ai/sora-2/video-to-video/remix`):
- **Category**: Video-to-Video
- **Input**: 
  - `video_id` (required) - ID from previous Sora 2 generation
  - `prompt` (required) - updated prompt for remix
  - `api_key` (optional)
- **Output**: `video` (VideoFile), `video_id` (string)
- **Use Case**: Transform existing Sora-generated videos with new prompts
- **Note**: Can only remix videos generated by Sora (via T2V/I2V), not arbitrary uploads
- **Status**: ✔️ Configured

**Qwen Image Edit** (`fal-ai/qwen-image-edit/image-to-image`):
- **Category**: Image-to-Image (Superior Text Editing)
- **Input**: 
  - `prompt` (required) - editing instruction
  - `image_url` (required) - image to edit
  - `image_size` (square_hd/square/portrait_4_3/portrait_16_9/landscape_4_3/landscape_16_9 or custom width/height)
  - `num_inference_steps` (default: 30)
  - `guidance_scale` (default: 4)
  - `strength` (0.0-1.0, default: 0.94) - transformation strength
  - `negative_prompt` (optional)
  - `acceleration` (none/regular/high, default: regular)
  - `num_images` (1-N, default: 1)
  - `seed` (optional)
- **Output**: `images` (list), `seed` (integer)
- **Use Case**: Superior text editing capabilities in images
- **Status**: ✔️ Configured

**Wan 2.5 Text-to-Image** (`fal-ai/wan-25-preview/text-to-image`):
- **Category**: Text-to-Image
- **Input**: 
  - `prompt` (required) - max 2000 characters
  - `negative_prompt` (optional) - max 500 characters
  - `image_size` (square_hd/square/portrait_4_3/portrait_16_9/landscape_4_3/landscape_16_9 or custom, total pixels 768×768 to 1440×1440)
  - `num_images` (1-4, default: 1)
  - `enable_prompt_expansion` (boolean, default: true)
  - `seed` (optional)
- **Output**: `images` (list), `seeds` (list), `actual_prompt` (string if expanded)
- **Use Case**: High-quality image generation with prompt expansion
- **Status**: ✔️ Configured

**Wan 2.5 Image-to-Image** (`fal-ai/wan-25-preview/image-to-image`):
- **Category**: Image-to-Image (Multi-Reference Fusion)
- **Input**: 
  - `prompt` (required) - editing instruction, max 2000 characters
  - `image_urls` (required) - 1-2 URLs (single edit or multi-reference generation)
  - `negative_prompt` (optional) - max 500 characters
  - `image_size` (square_hd/square/portrait_4_3/portrait_16_9/landscape_4_3/landscape_16_9, width/height 384-1440px)
  - `num_images` (1-4, default: 1)
  - `seed` (optional)
- **Output**: `images` (list), `seeds` (list), `actual_prompt` (string)
- **Use Case**: Subject-consistent editing, multi-image fusion
- **Status**: ✔️ Configured

**Wan 2.5 Text-to-Video** (`fal-ai/wan-25-preview/text-to-video`):
- **Category**: Text-to-Video
- **Input**: 
  - `prompt` (required) - max 800 characters
  - `aspect_ratio` (16:9/9:16/1:1, default: 16:9)
  - `resolution` (480p/720p/1080p, default: 1080p)
  - `duration` (5/10 seconds, default: 5)
  - `audio_url` (optional) - WAV/MP3, 3-30s, max 15MB
  - `negative_prompt` (optional) - max 500 characters
  - `enable_prompt_expansion` (boolean, default: true)
  - `seed` (optional)
- **Output**: `video` (VideoFile), `seed` (integer), `actual_prompt` (string if expanded)
- **Use Case**: Best visual quality and motion stability
- **Status**: ✔️ Configured

**Wan 2.5 Image-to-Video** (`fal-ai/wan-25-preview/image-to-video`):
- **Category**: Image-to-Video
- **Input**: 
  - `prompt` (required) - max 800 characters
  - `image_url` (required) - 360-2000px, max 10MB, JPEG/PNG/BMP/WEBP
  - `resolution` (480p/720p/1080p, default: 1080p)
  - `duration` (5/10 seconds, default: 5)
  - `audio_url` (optional) - WAV/MP3, 3-30s, max 15MB
  - `negative_prompt` (optional) - max 500 characters
  - `enable_prompt_expansion` (boolean, default: true)
  - `seed` (optional)
- **Output**: `video` (VideoFile), `seed` (integer), `actual_prompt` (string if expanded)
- **Use Case**: High-quality image animation with audio support
- **Processing Time**: 1-3 minutes
- **Status**: ✔️ Configured

**Luma Photon Flash Reframe** (`fal-ai/luma-photon/flash/reframe`):
- **Category**: Image Reframing (Aspect Ratio Change)
- **Input**: 
  - `image_url` (required) - input image to reframe
  - `aspect_ratio` (1:1/16:9/9:16/4:3/3:4/21:9/9:21)
  - `prompt` (optional) - optional reframing guidance
  - Grid position parameters (x/y start/end, optional)
- **Output**: `images` (list of File)
- **Use Case**: Intelligent image expansion and reframing
- **Speed**: Flash (very fast)
- **Status**: ✔️ Configured

**OmniHuman** (`fal-ai/bytedance/omnihuman`):
- **Category**: Avatar/Lipsync (Image + Audio → Video)
- **Input**: `image_url` (human image), `audio_url` (audio <30s)
- **Output**: `video` (File), `duration` (float)
- **Use Case**: Animate human image with audio, emotions match audio
- **Status**: 🆕 Needs to be added to Avatar category

**Wan 2.2 I2V LoRA** (`fal-ai/wan/v2.2-a14b/image-to-video/lora`):
- **Category**: Image-to-Video (with LoRA support)
- **Input**: 
  - `image_url` (required)
  - `prompt` (required)
  - `loras` (list of LoRA weights) - optional
  - `num_frames` (17-161, default: 81)
  - `frames_per_second` (4-60, default: 16)
  - `resolution` (480p/580p/720p, default: 720p)
  - `aspect_ratio` (auto/16:9/9:16/1:1, default: auto)
  - `guidance_scale` (default: 3.5)
  - `enable_prompt_expansion` (boolean)
  - `interpolator_model` (none/film/rife, default: film)
  - `video_quality` (low/medium/high/maximum, default: high)
- **Output**: `video` (File), `prompt` (string), `seed` (integer)
- **Use Case**: Generate high-quality videos from images with custom LoRA support
- **Status**: 🆕 Needs configuration in dropdown

**Lucy-14B** (`decart/lucy-14b/image-to-video`):
- **Category**: Image-to-Video (Lightning Fast)
- **Input**: 
  - `prompt` (required) - text description
  - `image_url` (required) - first frame image
  - `resolution` (720p only)
  - `aspect_ratio` (9:16 or 16:9, default: 16:9)
  - `sync_mode` (boolean, default: true)
- **Output**: `video` (File - MP4 with H.264 encoding)
- **Use Case**: Ultra-fast video generation, lightning performance
- **Special**: Simpler schema, optimized for speed
- **Status**: 🆕 High priority - add to dropdown

**LTX Video 0.9.8 13B** (`fal-ai/ltxv-13b-098-distilled/image-to-video`):
- **Category**: Image-to-Video (Long videos, LoRA support)
- **Input**: 
  - `prompt` (required)
  - `image_url` (required for I2V)
  - `loras` (list of LoRA weights) - optional
  - `num_frames` (default: 121) - supports long videos
  - `frame_rate` (default: 24)
  - `resolution` (480p/720p, default: 720p)
  - `aspect_ratio` (9:16/1:1/16:9/auto, default: auto)
  - `enable_detail_pass` (boolean) - 2x cost but enhanced details
  - `first_pass_num_inference_steps` (default: 8)
  - `second_pass_num_inference_steps` (default: 8)
  - `temporal_adain_factor` (0.0-1.0, default: 0.5) - color consistency
  - `expand_prompt` (boolean)
  - `reverse_video` (boolean)
- **Output**: `video` (File), `prompt` (string), `seed` (integer)
- **Use Case**: Long-form video generation with detail refinement
- **Special**: Detail pass option, temporal color normalization, LoRA support
- **Status**: ✅ Already configured

---

## 🎭 Video-to-Video Models (6 Configured)

### ✅ Already Configured
1. `endframe/minimax-hailuo-02` - EndFrame (Minimax)
2. `fal-ai/sora-2/video-to-video/remix` - Sora 2 Video Remix ✔️
3. `fal-ai/luma-dream-machine/ray-2/modify` - Luma Ray 2 Modify ✔️
4. `fal-ai/luma-dream-machine/ray-2-flash/modify` - Luma Ray 2 Flash Modify ✔️
5. `fal-ai/luma-dream-machine/ray-2/reframe` - Luma Ray 2 Reframe ✔️
6. `fal-ai/luma-dream-machine/ray-2-flash/reframe` - Luma Ray 2 Flash Reframe ✔️

### 🆕 New Models to Add
- `fal-ai/wan-vace-apps/long-reframe` - Wan VACE 2.1 Long Reframe
- `fal-ai/creatify/lipsync` - Creatify Lipsync (realistic, fast)
- `fal-ai/sync-lipsync/v2` - Sync Lipsync 2.0
- `fal-ai/pixverse/lipsync` - PixVerse Lipsync
- `fal-ai/mirelo-ai/sfx-v1/video-to-video` - Mirelo SFX v1 (video + sound)
- `fal-ai/bria/video/background-removal` - Bria Video Background Removal

---

## 🎤 Video-to-Audio Models

### 🆕 New Models to Add
- `fal-ai/kling-video/video-to-audio` - Kling Video-to-Audio
- `fal-ai/mirelo-ai/sfx-v1/video-to-audio` - Mirelo SFX v1 (sound only)

---

## 🔊 Audio / Music Models (2 Configured)

### ✅ Already Configured
1. `fal-ai/minimax-music/v1.5` - MiniMax Music v1.5 ✔️
2. `fal-ai/minimax-music` - MiniMax Music ✔️

### 🆕 New Models to Add
- `fal-ai/index-tts-2/text-to-speech` - Index TTS 2.0
- `fal-ai/chatterbox/text-to-speech` - Chatterbox TTS (Resemble AI)
- `fal-ai/playai/tts/dialog` - PlayAI Dialog TTS (multi-speaker)
- `fal-ai/minimax/speech-02-hd` - MiniMax Speech-02 HD
- `fal-ai/dia-tts/voice-clone` - Dia TTS Voice Clone

---

## 🎨 Image-to-Image / Image Editing

### 🆕 New Models to Add
- `fal-ai/dreamomni2/edit` - DreamOmni2 (text & image guided editing)
- `fal-ai/flux-pro/kontext` - Flux Kontext Pro (local edits, scene transforms)
- `fal-ai/flux-kontext-lora` - Flux Kontext LoRA
- `fal-ai/flux-kontext-lora/inpaint` - Flux Kontext LoRA Inpaint
- `fal-ai/flux-pro/kontext/max` - Flux Pro Kontext Max
- `fal-ai/flux-pro/kontext/max/multi` - Flux Pro Kontext Max Multi
- `fal-ai/flux-pro/kontext/multi` - Flux Pro Kontext Multi
- `fal-ai/topaz/upscale/image` - Topaz Image Upscaler
- `fal-ai/bria/background/remove` - Bria Background Removal

---

## 🎥 Avatar / Lipsync Models (4 Configured)

### ✅ Already Configured
- `fal-ai/kling-video/v1/pro/ai-avatar` - Kling AI Avatar Pro
- `fal-ai/sync-lipsync/v2` - Sync Lipsync 2.0 ✔️
- `veed/lipsync` - VEED Lipsync ✔️
- `fal-ai/bytedance/omnihuman` - OmniHuman (Avatar) ✔️

### 🆕 New Models to Add
- `fal-ai/creatify/lipsync` - Creatify Lipsync (speed + quality)
- `fal-ai/ai-avatar/single-text` - MultiTalk (image + text)
- `fal-ai/pixverse/lipsync` - PixVerse Lipsync

---

## 👁️ Vision / Detection Models

### 🆕 New Models to Add
- `fal-ai/moondream3-preview/detect` - Moondream 3 Detection
- `fal-ai/moondream3-preview/point` - Moondream 3 Pointing
- `fal-ai/moondream3-preview/query` - Moondream 3 Query
- `fal-ai/moondream3-preview/caption` - Moondream 3 Caption
- `fal-ai/x-ailab/nsfw` - NSFW Detection (safety filter)

---

## 🎓 Training / LoRA Models

### 🆕 New Models to Add (From Updated all models.txt)
- `fal-ai/flux-lora-portrait-trainer` - Flux LoRA Portrait Trainer
- `fal-ai/flux-kontext-trainer` - Flux Kontext LoRA Trainer
- `fal-ai/flux-lora-fast-training` - Flux LoRA Fast Training
- `fal-ai/wan-trainer/t2v-14b` - Wan Trainer T2V 14B
- `fal-ai/wan-trainer/t2v` - Wan Trainer T2V
- `fal-ai/wan-trainer/i2v-720p` - Wan Trainer I2V 720p
- `fal-ai/flux-pro-trainer` - Flux Pro Trainer
- `fal-ai/wan-22-image-trainer` - Wan 2.2 Image Trainer

---

## 🧊 3D Models (1 Configured)

### ✅ Already Configured
1. `fal-ai/meshy/v5/multi-image-to-3d` - Meshy V5 Multi-Image-to-3D ✔️

### 🆕 New Models to Add
- `fal-ai/hunyuan-part` - Hunyuan Part (3D to point cloud)
- `fal-ai/meshy/v6-preview/text-to-3d` - Meshy v6 Text-to-3D
- `fal-ai/meshy/v6-preview/image-to-3d` - Meshy v6 Image-to-3D

---

## 🛠️ Utility Models

### 🆕 New Models to Add
- `fal-ai/topaz/upscale/video` - Topaz Video Upscaler
- `fal-ai/bria/video/background-removal` - Bria Video BG Removal
- `fal-ai/bria/background/remove` - Bria Image BG Removal
- `fal-ai/x-ailab/nsfw` - NSFW Filter

---

## 📊 Summary

### Current Status (Updated with Wan 2.5, Qwen, and Luma Photon Models)
- **Total Models Listed**: ~65+ documented models
- **Already Configured**: 61 models (61% complete - over halfway!)
- **New Models to Add**: ~5 high-priority models remaining
- **Categories**: 12 categories
- **Breakdown by Category**:
  - Text-to-Image: 20 models (includes Wan 2.5 T2I, Qwen Edit, Luma Reframe)
  - Text-to-Video: 12 models (includes Wan 2.5 T2V, all Veo 3.1 variants)
  - Image-to-Video: 25 models (includes Wan 2.5 I2V, Veo 3.1 I2V variants)
  - Video-to-Video: 6 models
  - Audio/Music: 2 models
  - 3D: 1 model
  - Avatar: 1 model (Kling AI Avatar Pro)
  - Others: Pending implementation

### Priority Implementation Order
1. **High Priority**: Text-to-Video, Image-to-Video (most requested)
2. **Medium Priority**: Audio/TTS, Avatar/Lipsync
3. **Low Priority**: 3D, Training, Utility models

### Next Steps
1. Implement color-coded category tabs in dropdown
2. Add new models systematically by category
3. Configure API endpoints for each model
4. Test each model integration
5. Update documentation

---

## Color Coding Scheme (for UI)
- 🟦 **Text-to-Image**: Blue
- 🟪 **Text-to-Video**: Purple
- 🟩 **Image-to-Video**: Green
- 🟨 **Video-to-Video**: Yellow
- 🟧 **Video-to-Audio**: Orange
- 🟥 **Audio/TTS**: Red
- 🟫 **Avatar/Lipsync**: Brown
- ⬜ **Vision**: Light Gray
- ⬛ **3D Models**: Dark Gray
- 🟦 **Training**: Cyan
- 🟪 **Image Edit**: Magenta
- 🟩 **Utility**: Teal

---

## 📋 Implementation History

### Session 1 - Initial Setup (2025-01-14)
- ✅ Created model catalog structure
- ✅ Built color-coded ModelSelector component
- ✅ Documented all 100+ models by category
- **Models Configured**: 17

### Session 2 - Category Organization & New Models (2025-01-14)
- ✅ Added color-coded category headers in dropdown
- ✅ Created ModelSelectionModal with category cards
- ✅ Replaced dropdown with beautiful modal interface
- ✅ Added 35 new models across multiple categories
- **Models Added This Session**: 35
  - Text-to-Image: 13 new (Imagen 4, Recraft V3, HiDream, Flux Krea, DreamOmni2, Flux Kontext x7, Flux Pro Kontext x6)
  - Text-to-Video: 8 new (Sora 2 T2V x2, Kandinsky 5.0 x2, Ovi, Luma Dream Machine, Kling x2)
  - Image-to-Video: 12 new (Luma variants x5, PixVerse V5, LTX Video, Lucy-14B, Wan LoRA, OmniHuman)
  - Video-to-Video: 5 new (Sora 2 Remix, Luma Modify x2, Luma Reframe x2)
  - Audio: 2 new (MiniMax Music x2)
  - 3D: 1 new (Meshy V5)
- **Total Models Now**: 52
- **UI Update**: Beautiful modal with color-coded category cards

### Next Implementation Session
**Target**: Add Avatar/Lipsync and Audio/TTS models
- [ ] Creatify Lipsync
- [ ] Sync Lipsync 2.0
- [ ] PixVerse Lipsync
- [ ] Index TTS 2.0
- [ ] Chatterbox TTS
- [ ] PlayAI Dialog TTS

---

## 🎯 Quick Reference by Status

### Current Dropdown Models (17)
1. fal-ai/nano-banana/edit
2. fal-ai/bytedance/seedream/v4/edit
3. fal-ai/flux-pro/v1.1-ultra
4. fal-ai/sora-2/image-to-video
5. fal-ai/sora-2/image-to-video/pro
6. fal-ai/veo3/image-to-video
7. fal-ai/kling-video/v2.1/master/image-to-video
8. fal-ai/kling-video/v2.5-turbo/pro/image-to-video
9. fal-ai/minimax/hailuo-02/standard/image-to-video
10. fal-ai/hunyuan-video
11. fal-ai/wan-pro/image-to-video (disabled)
12. fal-ai/wan/v2.2-a14b/image-to-video
13. fal-ai/ovi/image-to-video
14. fal-ai/luma-dream-machine/ray-2/image-to-video
15. fal-ai/wan-25-preview/image-to-video
16. fal-ai/kling-video/v1/pro/ai-avatar
17. endframe/minimax-hailuo-02

### High Priority Next Adds
1. Text-to-Video models (high demand)
2. Audio/TTS models (complementary to video)
3. Image editing models (Flux Kontext, DreamOmni2)
4. Avatar/Lipsync models (user engagement)

---

## 🆕 NEW MODELS FROM ALL MODELS.TXT (38 Models)

### 📸 Text-to-Image Models (New)
1. `fal-ai/imagen4/preview` - Google Imagen 4 (highest quality, 1K/2K resolution)
   - **Input**: prompt, negative_prompt, aspect_ratio (1:1, 16:9, 9:16, 3:4, 4:3), num_images (1-4), seed, resolution (1K, 2K)
   - **Output**: images[], seed
   - **Use Case**: Highest quality image generation with enhanced detail and lighting

2. `fal-ai/flux-pro/kontext/max/text-to-image` - Flux Pro Kontext Max (advanced context)
   - **Input**: prompt, negative_prompt, aspect_ratio, num_images, seed, resolution
   - **Output**: images[], seed
   - **Use Case**: Advanced Flux Pro with maximum context understanding

3. `fal-ai/flux-krea-lora/stream` - Flux Krea LoRA Stream
   - **Input**: prompt, negative_prompt, aspect_ratio, num_images, seed, resolution
   - **Output**: images[], seed
   - **Use Case**: Flux with Krea LoRA streaming capabilities

4. `fal-ai/recraft/v3/text-to-image` - Recraft V3 Text-to-Image
   - **Input**: prompt, negative_prompt, aspect_ratio, num_images, seed, resolution
   - **Output**: images[], seed
   - **Use Case**: Professional design and illustration generation

5. `fal-ai/hidream-i1-full` - HiDream I1 Full
   - **Input**: prompt, negative_prompt, aspect_ratio, num_images, seed, resolution
   - **Output**: images[], seed
   - **Use Case**: High-detail dream-like image generation

6. `fal-ai/flux-kontext-lora/text-to-image` - Flux Kontext LoRA Text-to-Image
   - **Input**: prompt, negative_prompt, aspect_ratio, num_images, seed, resolution
   - **Output**: images[], seed
   - **Use Case**: Flux with Kontext LoRA for enhanced context

7. `fal-ai/flux-pro/kontext/text-to-image` - Flux Pro Kontext Text-to-Image
   - **Input**: prompt, negative_prompt, aspect_ratio, num_images, seed, resolution
   - **Output**: images[], seed
   - **Use Case**: Flux Pro with context understanding

8. `fal-ai/flux-pro/kontext/multi` - Flux Pro Kontext Multi
   - **Input**: prompt, negative_prompt, aspect_ratio, num_images, seed, resolution
   - **Output**: images[], seed
   - **Use Case**: Multi-context Flux Pro generation

### 🎬 Text-to-Video Models (New)
9. `fal-ai/kandinsky5/text-to-video` - Kandinsky 5 Text-to-Video
   - **Input**: prompt, negative_prompt, aspect_ratio, duration, resolution, seed
   - **Output**: video, seed
   - **Use Case**: Kandinsky-style video generation

10. `fal-ai/minimax-music/v1.5` - Minimax Music V1.5
    - **Input**: prompt, duration, style, seed
    - **Output**: audio, seed
    - **Use Case**: AI music generation with style control

11. `fal-ai/minimax-music` - Minimax Music
    - **Input**: prompt, duration, style, seed
    - **Output**: audio, seed
    - **Use Case**: AI music generation

12. `fal-ai/wan-trainer/t2v-14b` - Wan Trainer T2V 14B
    - **Input**: prompt, aspect_ratio, duration, resolution, seed
    - **Output**: video, seed
    - **Use Case**: Text-to-video with 14B parameter model

13. `fal-ai/wan-trainer/t2v` - Wan Trainer T2V
    - **Input**: prompt, aspect_ratio, duration, resolution, seed
    - **Output**: video, seed
    - **Use Case**: Text-to-video training model

### 🖼️ Image-to-Video Models (New)
14. `fal-ai/wan-trainer/i2v-720p` - Wan Trainer I2V 720p
    - **Input**: prompt, image_url, aspect_ratio, duration, resolution, seed
    - **Output**: video, seed
    - **Use Case**: Image-to-video at 720p resolution

### 🎨 Image Editing Models (New)
15. `fal-ai/dreamomni2/edit` - DreamOmni2 Edit
    - **Input**: prompt, image_url, strength, aspect_ratio, seed
    - **Output**: images[], seed
    - **Use Case**: Advanced image editing with DreamOmni2

16. `fal-ai/flux-kontext-lora/inpaint` - Flux Kontext LoRA Inpaint
    - **Input**: prompt, image_url, mask_url, strength, seed
    - **Output**: images[], seed
    - **Use Case**: Inpainting with Flux Kontext LoRA

17. `fal-ai/luma-dream-machine/ray-2-flash/modify` - Luma Ray 2 Flash Modify
    - **Input**: prompt, image_url, strength, aspect_ratio, seed
    - **Output**: images[], seed
    - **Use Case**: Fast image modification with Luma Ray 2 Flash

18. `fal-ai/luma-dream-machine/ray-2/modify` - Luma Ray 2 Modify
    - **Input**: prompt, image_url, strength, aspect_ratio, seed
    - **Output**: images[], seed
    - **Use Case**: Image modification with Luma Ray 2

### 🔄 Reframe Models (New)
19. `fal-ai/luma-dream-machine/ray-2-flash/reframe` - Luma Ray 2 Flash Reframe
    - **Input**: image_url, aspect_ratio, prompt, seed
    - **Output**: images[], seed
    - **Use Case**: Fast image reframing with Luma Ray 2 Flash

20. `fal-ai/luma-dream-machine/ray-2/reframe` - Luma Ray 2 Reframe
    - **Input**: image_url, aspect_ratio, prompt, seed
    - **Output**: images[], seed
    - **Use Case**: Image reframing with Luma Ray 2

### 🎭 Specialized Models (New)
21. `fal-ai/moondream3-preview/detect` - MoonDream3 Preview Detect
    - **Input**: image_url, prompt
    - **Output**: detections[], confidence
    - **Use Case**: Object detection and analysis

22. `fal-ai/meshy/v5/multi-image-to-3d` - Meshy V5 Multi-Image-to-3D
    - **Input**: image_urls[], prompt, quality, seed
    - **Output**: model_url, seed
    - **Use Case**: 3D model generation from multiple images

23. `fal-ai/bytedance/omnihuman` - ByteDance OmniHuman
    - **Input**: prompt, aspect_ratio, duration, resolution, seed
    - **Output**: video, seed
    - **Use Case**: Human-focused video generation

### 🔧 Advanced Flux Models (New)
24. `fal-ai/flux-kontext-lora` - Flux Kontext LoRA
    - **Input**: prompt, negative_prompt, aspect_ratio, num_images, seed, resolution
    - **Output**: images[], seed
    - **Use Case**: Flux with Kontext LoRA capabilities

25. `fal-ai/flux-pro/kontext/max` - Flux Pro Kontext Max
    - **Input**: prompt, negative_prompt, aspect_ratio, num_images, seed, resolution
    - **Output**: images[], seed
    - **Use Case**: Maximum context Flux Pro

26. `fal-ai/flux-pro/kontext/max/multi` - Flux Pro Kontext Max Multi
    - **Input**: prompt, negative_prompt, aspect_ratio, num_images, seed, resolution
    - **Output**: images[], seed
    - **Use Case**: Multi-context maximum Flux Pro

27. `fal-ai/wan-alpha` - Wan Alpha (Transparent Backgrounds)
    - **Input**: prompt, num_frames (81), fps (16), num_inference_steps (8), seed, sampler (euler/unipc/dpm++), shift (10.5), resolution (240p-720p), aspect_ratio (16:9/1:1/9:16), enable_prompt_expansion, enable_safety_checker, mask_clamp_lower (0.1), mask_clamp_upper (0.75), binarize_mask, mask_binarization_threshold (0.8), video_output_type (X264/VP9/PRORES4444/GIF), video_quality (low/medium/high/maximum), video_write_mode (fast/balanced/small), sync_mode
    - **Output**: video, mask, image, prompt, seed
    - **Use Case**: Generate videos with transparent backgrounds for compositing

28. `fal-ai/reve/text-to-image` - Reve Text-to-Image
    - **Input**: prompt (string), aspect_ratio (16:9/9:16/3:2/2:3/4:3/3:4/1:1, default: 3:2), output_format (png/jpeg/webp, default: png), sync_mode (boolean)
    - **Output**: images[] (url, content_type, file_name, file_size, width, height)
    - **Use Case**: Generate detailed visual output with strong aesthetic quality and accurate text rendering

29. `fal-ai/reve/edit` - Reve Edit (Image-to-Image)
    - **Input**: prompt (string), image_url (string, required - PNG/JPEG/WebP/AVIF/HEIF formats), output_format (png/jpeg/webp, default: png), sync_mode (boolean)
    - **Output**: images[] (url, content_type, file_name, file_size, width, height)
    - **Use Case**: Transform existing images via text prompts with strong aesthetic quality

30. `fal-ai/reve/remix` - Reve Remix (Multi-Image Composition)
    - **Input**: prompt (string, may include <img>0</img> XML tags), image_urls (list[string], 1-4 images, max 1.5MB each), aspect_ratio (16:9/9:16/3:2/2:3/4:3/3:4/1:1, optional - smartly chosen by model), output_format (png/jpeg/webp, default: png), sync_mode (boolean)
    - **Output**: images[] (url, content_type, file_name, file_size, width, height)
    - **Use Case**: Combine multiple reference images with text prompts for complex compositions

### 📊 Model Summary
- **Total New Models**: 30
- **Text-to-Image**: 11 models
- **Text-to-Video**: 6 models  
- **Image-to-Video**: 1 model
- **Image Editing**: 4 models
- **Reframe**: 2 models
- **Specialized**: 3 models
- **Advanced Flux**: 3 models

### 🎯 Implementation Priority
1. **High Priority**: Imagen 4, Kandinsky 5, Minimax Music, DreamOmni2 Edit
2. **Medium Priority**: Flux Kontext models, Luma reframe models
3. **Specialized**: MoonDream3, Meshy 3D, OmniHuman

