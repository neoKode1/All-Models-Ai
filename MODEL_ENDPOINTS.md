# AI Model Endpoints Catalog

> **Last Updated**: 2025-01-14 (Session 2 - Final)
> 
> **Progress**: 49/100+ models configured (49%)

## Status Legend
- ✅ **Already Configured** - Model is currently in the dropdown
- 🆕 **New Model** - Needs to be added
- 🔄 **Update Available** - Newer version available
- ⚙️ **In Progress** - Currently being configured
- ✔️ **Recently Added** - Added in last update session

## Implementation Workflow
1. Select models to implement from a category
2. Add models to dropdown with proper configuration
3. Test the integration
4. Update this markdown with ✔️ status
5. Move to next batch

---

## 📸 Text-to-Image Models

### ✅ Already Configured
- `fal-ai/imagen4/preview` - Google Imagen 4 ✔️ NEW
- `fal-ai/flux-pro/v1.1-ultra` - Flux Pro Ultra
- `fal-ai/recraft/v3/text-to-image` - Recraft V3 ✔️ NEW
- `fal-ai/hidream-i1-full` - HiDream-I1 ✔️ NEW
- `fal-ai/flux-krea-lora/stream` - Flux Krea LoRA Stream ✔️ NEW
- `fal-ai/nano-banana/edit` - Nano Banana Edit
- `fal-ai/bytedance/seedream/v4/edit` - Seedream 4.0 Edit
- `fal-ai/dreamomni2/edit` - DreamOmni2 Edit ✔️ NEW
- `fal-ai/flux-kontext-lora` - Flux Kontext LoRA ✔️ NEW
- `fal-ai/flux-kontext-lora/text-to-image` - Flux Kontext LoRA T2I ✔️ NEW

- `fal-ai/flux-kontext-lora/inpaint` - Flux Kontext Inpaint ✔️ NEW
- `fal-ai/flux-pro/kontext/max/text-to-image` - Flux Pro Kontext Max T2I ✔️ NEW
- `fal-ai/flux-pro/kontext/text-to-image` - Flux Pro Kontext T2I ✔️ NEW
- `fal-ai/flux-pro/kontext/max` - Flux Pro Kontext Max ✔️ NEW
- `fal-ai/flux-pro/kontext/max/multi` - Flux Pro Kontext Max Multi ✔️ NEW
- `fal-ai/flux-pro/kontext/multi` - Flux Pro Kontext Multi ✔️ NEW

### 🆕 New Models to Add
- `fal-ai/luma-photon` - Luma Photon (creative, personalizable)
- `fal-ai/gemini-25-flash-image` - Gemini 2.5 Flash
- `fal-ai/stable-diffusion-v35-large` - Stable Diffusion 3.5 Large
- `fal-ai/qwen-image` - Qwen Image (complex text rendering)

---

## 🎬 Text-to-Video Models

### ✅ Already Configured
- `fal-ai/sora-2/text-to-video` - Sora 2 T2V ✔️ NEW
- `fal-ai/sora-2/text-to-video/pro` - Sora 2 Pro T2V ✔️ NEW
- `fal-ai/kandinsky5/text-to-video` - Kandinsky 5.0 ✔️ NEW
- `fal-ai/kandinsky5/text-to-video/distill` - Kandinsky 5.0 Distilled ✔️ NEW
- `fal-ai/ovi` - Ovi (Audio-Video) ✔️ NEW
- `fal-ai/luma-dream-machine` - Luma Dream Machine v1.5 ✔️ NEW
- `fal-ai/kling-video/v2.5-turbo/pro/text-to-video` - Kling 2.5 Turbo Pro ✔️ NEW
- `fal-ai/kling-video/v2.1/master/text-to-video` - Kling 2.1 Master T2V ✔️ NEW

### 🆕 New Models to Add
- `fal-ai/veo3` - Veo 3 by Google (with sound)
- `fal-ai/hunyuan-video` - Hunyuan Video (open, high quality)

---

## 🖼️ Image-to-Video Models

### ✅ Already Configured
- `fal-ai/sora-2/image-to-video` - Sora 2 I2V
- `fal-ai/sora-2/image-to-video/pro` - Sora 2 Pro I2V
- `fal-ai/veo3/image-to-video` - Veo 3 I2V
- `fal-ai/kling-video/v2.1/master/image-to-video` - Kling v2.1 Master I2V ✔️ UPDATED
- `fal-ai/kling-video/v2.5-turbo/pro/image-to-video` - Kling V2.5 Turbo Pro I2V
- `fal-ai/minimax/hailuo-02/standard/image-to-video` - Minimax Hailuo 02 I2V
- `fal-ai/hunyuan-video` - Hunyuan Video I2V
- `fal-ai/wan/v2.2-a14b/image-to-video` - Wan v2.2-A14B I2V
- `fal-ai/ovi/image-to-video` - Ovi I2V (with audio)
- `fal-ai/luma-dream-machine/ray-2/image-to-video` - Luma Ray 2 I2V
- `fal-ai/wan-25-preview/image-to-video` - Wan 2.5 Preview I2V
- `fal-ai/luma-dream-machine/image-to-video` - Luma Dream Machine I2V ✔️ NEW
- `fal-ai/luma-dream-machine/ray-2` - Luma Ray 2 ✔️ NEW
- `fal-ai/luma-dream-machine/ray-2-flash` - Luma Ray 2 Flash ✔️ NEW
- `fal-ai/luma-dream-machine/ray-2-flash/image-to-video` - Luma Ray 2 Flash I2V ✔️ NEW
- `fal-ai/pixverse/v5/image-to-video` - PixVerse V5 I2V ✔️ NEW
- `fal-ai/ltxv-13b-098-distilled/image-to-video` - LTX Video 0.9.8 13B ✔️ NEW

- `decart/lucy-14b/image-to-video` - Lucy-14B (lightning fast) ✔️ NEW
- `fal-ai/wan/v2.2-a14b/image-to-video/lora` - Wan 2.2 I2V LoRA ✔️ NEW
- `fal-ai/bytedance/omnihuman` - OmniHuman (Image+Audio→Video) ✔️ NEW

### 🆕 New Models to Add
- `fal-ai/kling-video/v2.1/pro/image-to-video` - Kling 2.1 Pro I2V
- `fal-ai/ltx-video-13b-distilled/image-to-video` - LTX Video 0.9.7 13B Distilled

### 📋 Model Configuration Notes

**OmniHuman** (`fal-ai/bytedance/omnihuman`):
- **Category**: Avatar/Lipsync (Image + Audio → Video)
- **Input**: `image_url` (human image), `audio_url` (audio <30s)
- **Output**: `video` (File), `duration` (float)
- **Use Case**: Animate human image with audio, emotions match audio
- **Status**: 🆕 Needs to be added to Avatar category

**Wan 2.2 I2V LoRA** (`fal-ai/wan/v2.2-a14b/image-to-video/lora`):
- **Category**: Image-to-Video (with LoRA support)
- **Input**: 
  - `image_url` (required)
  - `prompt` (required)
  - `loras` (list of LoRA weights) - optional
  - `num_frames` (17-161, default: 81)
  - `frames_per_second` (4-60, default: 16)
  - `resolution` (480p/580p/720p, default: 720p)
  - `aspect_ratio` (auto/16:9/9:16/1:1, default: auto)
  - `guidance_scale` (default: 3.5)
  - `enable_prompt_expansion` (boolean)
  - `interpolator_model` (none/film/rife, default: film)
  - `video_quality` (low/medium/high/maximum, default: high)
- **Output**: `video` (File), `prompt` (string), `seed` (integer)
- **Use Case**: Generate high-quality videos from images with custom LoRA support
- **Status**: 🆕 Needs configuration in dropdown

**Lucy-14B** (`decart/lucy-14b/image-to-video`):
- **Category**: Image-to-Video (Lightning Fast)
- **Input**: 
  - `prompt` (required) - text description
  - `image_url` (required) - first frame image
  - `resolution` (720p only)
  - `aspect_ratio` (9:16 or 16:9, default: 16:9)
  - `sync_mode` (boolean, default: true)
- **Output**: `video` (File - MP4 with H.264 encoding)
- **Use Case**: Ultra-fast video generation, lightning performance
- **Special**: Simpler schema, optimized for speed
- **Status**: 🆕 High priority - add to dropdown

**LTX Video 0.9.8 13B** (`fal-ai/ltxv-13b-098-distilled/image-to-video`):
- **Category**: Image-to-Video (Long videos, LoRA support)
- **Input**: 
  - `prompt` (required)
  - `image_url` (required for I2V)
  - `loras` (list of LoRA weights) - optional
  - `num_frames` (default: 121) - supports long videos
  - `frame_rate` (default: 24)
  - `resolution` (480p/720p, default: 720p)
  - `aspect_ratio` (9:16/1:1/16:9/auto, default: auto)
  - `enable_detail_pass` (boolean) - 2x cost but enhanced details
  - `first_pass_num_inference_steps` (default: 8)
  - `second_pass_num_inference_steps` (default: 8)
  - `temporal_adain_factor` (0.0-1.0, default: 0.5) - color consistency
  - `expand_prompt` (boolean)
  - `reverse_video` (boolean)
- **Output**: `video` (File), `prompt` (string), `seed` (integer)
- **Use Case**: Long-form video generation with detail refinement
- **Special**: Detail pass option, temporal color normalization, LoRA support
- **Status**: ✅ Already configured

---

## 🎭 Video-to-Video Models

### ✅ Already Configured
- `endframe/minimax-hailuo-02` - EndFrame (Minimax)
- `fal-ai/sora-2/video-to-video/remix` - Sora 2 Video Remix ✔️ NEW
- `fal-ai/luma-dream-machine/ray-2/modify` - Luma Ray 2 Modify ✔️ NEW
- `fal-ai/luma-dream-machine/ray-2-flash/modify` - Luma Ray 2 Flash Modify ✔️ NEW
- `fal-ai/luma-dream-machine/ray-2/reframe` - Luma Ray 2 Reframe ✔️ NEW
- `fal-ai/luma-dream-machine/ray-2-flash/reframe` - Luma Ray 2 Flash Reframe ✔️ NEW

### 🆕 New Models to Add
- `fal-ai/wan-vace-apps/long-reframe` - Wan VACE 2.1 Long Reframe
- `fal-ai/creatify/lipsync` - Creatify Lipsync (realistic, fast)
- `fal-ai/sync-lipsync/v2` - Sync Lipsync 2.0
- `fal-ai/pixverse/lipsync` - PixVerse Lipsync
- `fal-ai/mirelo-ai/sfx-v1/video-to-video` - Mirelo SFX v1 (video + sound)
- `fal-ai/bria/video/background-removal` - Bria Video Background Removal

---

## 🎤 Video-to-Audio Models

### 🆕 New Models to Add
- `fal-ai/kling-video/video-to-audio` - Kling Video-to-Audio
- `fal-ai/mirelo-ai/sfx-v1/video-to-audio` - Mirelo SFX v1 (sound only)

---

## 🔊 Text-to-Speech / Audio Models

### ✅ Already Configured
- `fal-ai/minimax-music/v1.5` - MiniMax Music v1.5 ✔️ NEW
- `fal-ai/minimax-music` - MiniMax Music ✔️ NEW

### 🆕 New Models to Add
- `fal-ai/index-tts-2/text-to-speech` - Index TTS 2.0
- `fal-ai/chatterbox/text-to-speech` - Chatterbox TTS (Resemble AI)
- `fal-ai/playai/tts/dialog` - PlayAI Dialog TTS (multi-speaker)
- `fal-ai/minimax/speech-02-hd` - MiniMax Speech-02 HD
- `fal-ai/dia-tts/voice-clone` - Dia TTS Voice Clone

---

## 🎨 Image-to-Image / Image Editing

### 🆕 New Models to Add
- `fal-ai/dreamomni2/edit` - DreamOmni2 (text & image guided editing)
- `fal-ai/flux-pro/kontext` - Flux Kontext Pro (local edits, scene transforms)
- `fal-ai/flux-kontext-lora` - Flux Kontext LoRA
- `fal-ai/flux-kontext-lora/inpaint` - Flux Kontext LoRA Inpaint
- `fal-ai/flux-pro/kontext/max` - Flux Pro Kontext Max
- `fal-ai/flux-pro/kontext/max/multi` - Flux Pro Kontext Max Multi
- `fal-ai/flux-pro/kontext/multi` - Flux Pro Kontext Multi
- `fal-ai/topaz/upscale/image` - Topaz Image Upscaler
- `fal-ai/bria/background/remove` - Bria Background Removal

---

## 🎥 Avatar / Lipsync Models

### ✅ Already Configured
- `fal-ai/kling-video/v1/pro/ai-avatar` - Kling AI Avatar Pro

### 🆕 New Models to Add
- `fal-ai/creatify/lipsync` - Creatify Lipsync (speed + quality)
- `fal-ai/bytedance/omnihuman` - OmniHuman (human + audio)
- `fal-ai/ai-avatar/single-text` - MultiTalk (image + text)
- `fal-ai/sync-lipsync/v2` - Sync Lipsync 2.0
- `fal-ai/pixverse/lipsync` - PixVerse Lipsync

---

## 👁️ Vision / Detection Models

### 🆕 New Models to Add
- `fal-ai/moondream3-preview/detect` - Moondream 3 Detection
- `fal-ai/moondream3-preview/point` - Moondream 3 Pointing
- `fal-ai/moondream3-preview/query` - Moondream 3 Query
- `fal-ai/moondream3-preview/caption` - Moondream 3 Caption
- `fal-ai/x-ailab/nsfw` - NSFW Detection (safety filter)

---

## 🎓 Training / LoRA Models

### 🆕 New Models to Add (From Updated all models.txt)
- `fal-ai/flux-lora-portrait-trainer` - Flux LoRA Portrait Trainer
- `fal-ai/flux-kontext-trainer` - Flux Kontext LoRA Trainer
- `fal-ai/flux-lora-fast-training` - Flux LoRA Fast Training
- `fal-ai/wan-trainer/t2v-14b` - Wan Trainer T2V 14B
- `fal-ai/wan-trainer/t2v` - Wan Trainer T2V
- `fal-ai/wan-trainer/i2v-720p` - Wan Trainer I2V 720p
- `fal-ai/flux-pro-trainer` - Flux Pro Trainer
- `fal-ai/wan-22-image-trainer` - Wan 2.2 Image Trainer

---

## 🧊 3D Models

### ✅ Already Configured
- `fal-ai/meshy/v5/multi-image-to-3d` - Meshy V5 Multi-Image-to-3D ✔️ NEW

### 🆕 New Models to Add
- `fal-ai/hunyuan-part` - Hunyuan Part (3D to point cloud)
- `fal-ai/meshy/v6-preview/text-to-3d` - Meshy v6 Text-to-3D
- `fal-ai/meshy/v6-preview/image-to-3d` - Meshy v6 Image-to-3D

---

## 🛠️ Utility Models

### 🆕 New Models to Add
- `fal-ai/topaz/upscale/video` - Topaz Video Upscaler
- `fal-ai/bria/video/background-removal` - Bria Video BG Removal
- `fal-ai/bria/background/remove` - Bria Image BG Removal
- `fal-ai/x-ailab/nsfw` - NSFW Filter

---

## 📊 Summary

### Current Status (Updated from all models.txt)
- **Total Models Listed**: ~45+ documented models
- **Already Configured**: 38 models (38% complete)
- **New Models to Add**: 10+ high-priority models
- **Categories**: 12 categories
- **New Models Identified**: Flux Pro Kontext variants, Wan Trainer variants, Kling 2.1 Master T2V

### Priority Implementation Order
1. **High Priority**: Text-to-Video, Image-to-Video (most requested)
2. **Medium Priority**: Audio/TTS, Avatar/Lipsync
3. **Low Priority**: 3D, Training, Utility models

### Next Steps
1. Implement color-coded category tabs in dropdown
2. Add new models systematically by category
3. Configure API endpoints for each model
4. Test each model integration
5. Update documentation

---

## Color Coding Scheme (for UI)
- 🟦 **Text-to-Image**: Blue
- 🟪 **Text-to-Video**: Purple
- 🟩 **Image-to-Video**: Green
- 🟨 **Video-to-Video**: Yellow
- 🟧 **Video-to-Audio**: Orange
- 🟥 **Audio/TTS**: Red
- 🟫 **Avatar/Lipsync**: Brown
- ⬜ **Vision**: Light Gray
- ⬛ **3D Models**: Dark Gray
- 🟦 **Training**: Cyan
- 🟪 **Image Edit**: Magenta
- 🟩 **Utility**: Teal

---

## 📋 Implementation History

### Session 1 - Initial Setup (2025-01-14)
- ✅ Created model catalog structure
- ✅ Built color-coded ModelSelector component
- ✅ Documented all 100+ models by category
- **Models Configured**: 17

### Session 2 - Category Organization & New Models (2025-01-14)
- ✅ Added color-coded category headers in dropdown
- ✅ Reorganized models by category with visual separators
- ✅ Added 32 new models across multiple categories
- **Models Added This Session**: 32
  - Text-to-Image: 13 new (Imagen 4, Recraft V3, HiDream, Flux Krea, DreamOmni2, Flux Kontext x7)
  - Text-to-Video: 8 new (Sora 2 T2V x2, Kandinsky 5.0 x2, Ovi, Luma Dream Machine, Kling x2)
  - Image-to-Video: 9 new (Luma variants x5, PixVerse V5, LTX Video, Lucy-14B, Wan LoRA, OmniHuman)
  - Video-to-Video: 5 new (Sora 2 Remix, Luma Modify x2, Luma Reframe x2)
  - Audio: 2 new (MiniMax Music x2)
  - 3D: 1 new (Meshy V5)
- **Total Models Now**: 49

### Next Implementation Session
**Target**: Add Avatar/Lipsync and Audio/TTS models
- [ ] Creatify Lipsync
- [ ] Sync Lipsync 2.0
- [ ] PixVerse Lipsync
- [ ] Index TTS 2.0
- [ ] Chatterbox TTS
- [ ] PlayAI Dialog TTS

---

## 🎯 Quick Reference by Status

### Current Dropdown Models (17)
1. fal-ai/nano-banana/edit
2. fal-ai/bytedance/seedream/v4/edit
3. fal-ai/flux-pro/v1.1-ultra
4. fal-ai/sora-2/image-to-video
5. fal-ai/sora-2/image-to-video/pro
6. fal-ai/veo3/image-to-video
7. fal-ai/kling-video/v2.1/master/image-to-video
8. fal-ai/kling-video/v2.5-turbo/pro/image-to-video
9. fal-ai/minimax/hailuo-02/standard/image-to-video
10. fal-ai/hunyuan-video
11. fal-ai/wan-pro/image-to-video (disabled)
12. fal-ai/wan/v2.2-a14b/image-to-video
13. fal-ai/ovi/image-to-video
14. fal-ai/luma-dream-machine/ray-2/image-to-video
15. fal-ai/wan-25-preview/image-to-video
16. fal-ai/kling-video/v1/pro/ai-avatar
17. endframe/minimax-hailuo-02

### High Priority Next Adds
1. Text-to-Video models (high demand)
2. Audio/TTS models (complementary to video)
3. Image editing models (Flux Kontext, DreamOmni2)
4. Avatar/Lipsync models (user engagement)

