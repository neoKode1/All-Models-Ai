# AI Model Endpoints Catalog

> **Last Updated**: 2025-01-14
> 
> **Progress**: 17/100+ models configured (17%)

## Status Legend
- ✅ **Already Configured** - Model is currently in the dropdown
- 🆕 **New Model** - Needs to be added
- 🔄 **Update Available** - Newer version available
- ⚙️ **In Progress** - Currently being configured
- ✔️ **Recently Added** - Added in last update session

## Implementation Workflow
1. Select models to implement from a category
2. Add models to dropdown with proper configuration
3. Test the integration
4. Update this markdown with ✔️ status
5. Move to next batch

---

## 📸 Text-to-Image Models

### ✅ Already Configured
- `fal-ai/nano-banana/edit` - Nano Banana Edit (Google)
- `fal-ai/bytedance/seedream/v4/edit` - Seedream 4.0 Edit
- `fal-ai/flux-pro/v1.1-ultra` - Flux Pro

### 🆕 New Models to Add
- `fal-ai/imagen4/preview` - Google Imagen 4 (highest quality)
- `fal-ai/recraft/v3/text-to-image` - Recraft V3 (SOTA, vector art, typography)
- `fal-ai/hidream-i1-full` - HiDream-I1 (17B parameters, open-source)
- `fal-ai/luma-photon` - Luma Photon (creative, personalizable)
- `fal-ai/gemini-25-flash-image` - Gemini 2.5 Flash
- `fal-ai/stable-diffusion-v35-large` - Stable Diffusion 3.5 Large
- `fal-ai/qwen-image` - Qwen Image (complex text rendering)
- `fal-ai/flux-kontext-lora/text-to-image` - Flux Kontext LoRA
- `fal-ai/flux-pro/kontext/max/text-to-image` - Flux Pro Kontext Max
- `fal-ai/flux-krea-lora/stream` - Flux Krea LoRA Stream (super fast)

---

## 🎬 Text-to-Video Models

### 🆕 New Models to Add
- `fal-ai/kandinsky5/text-to-video` - Kandinsky 5.0
- `fal-ai/kandinsky5/text-to-video/distill` - Kandinsky 5.0 Distilled (lightweight)
- `fal-ai/veo3` - Veo 3 by Google (with sound)
- `fal-ai/ovi` - Ovi (unified audio-video generation)
- `fal-ai/luma-dream-machine` - Luma Dream Machine v1.5
- `fal-ai/hunyuan-video` - Hunyuan Video (open, high quality)
- `fal-ai/kling-video/v2.5-turbo/pro/text-to-video` - Kling 2.5 Turbo Pro
- `fal-ai/sora-2/text-to-video` - Sora 2 Text-to-Video
- `fal-ai/sora-2/text-to-video/pro` - Sora 2 Pro Text-to-Video

---

## 🖼️ Image-to-Video Models

### ✅ Already Configured
- `fal-ai/sora-2/image-to-video` - Sora 2 I2V
- `fal-ai/sora-2/image-to-video/pro` - Sora 2 Pro I2V
- `fal-ai/veo3/image-to-video` - Veo 3 I2V
- `fal-ai/kling-video/v2.1/master/image-to-video` - Kling v2.1 Master I2V
- `fal-ai/kling-video/v2.5-turbo/pro/image-to-video` - Kling V2.5 Turbo Pro I2V
- `fal-ai/minimax/hailuo-02/standard/image-to-video` - Minimax Hailuo 02 I2V
- `fal-ai/hunyuan-video` - Hunyuan Video I2V
- `fal-ai/wan/v2.2-a14b/image-to-video` - Wan v2.2-A14B I2V
- `fal-ai/ovi/image-to-video` - Ovi I2V (with audio)
- `fal-ai/luma-dream-machine/ray-2/image-to-video` - Luma Ray 2 I2V
- `fal-ai/wan-25-preview/image-to-video` - Wan 2.5 Preview I2V

### 🆕 New Models to Add
- `fal-ai/decart/lucy-5b/image-to-video` - Lucy-5B (5-sec videos in <5 sec)
- `fal-ai/kling-video/v2.1/pro/image-to-video` - Kling 2.1 Pro I2V
- `fal-ai/pixverse/v5/image-to-video` - PixVerse v5 I2V
- `fal-ai/ltxv-13b-098-distilled/image-to-video` - LTX Video 0.9.8 13B Distilled
- `fal-ai/ltx-video-13b-distilled/image-to-video` - LTX Video 0.9.7 13B Distilled
- `fal-ai/bytedance/omnihuman` - OmniHuman (human + audio)
- `fal-ai/ai-avatar/single-text` - MultiTalk Avatar (image + text)
- `fal-ai/wan/v2.2-a14b/image-to-video/lora` - Wan 2.2 I2V with LoRA support

---

## 🎭 Video-to-Video Models

### ✅ Already Configured
- `endframe/minimax-hailuo-02` - EndFrame (Minimax)

### 🆕 New Models to Add
- `fal-ai/sora-2/video-to-video/remix` - Sora 2 Video Remix
- `fal-ai/wan-vace-apps/long-reframe` - Wan VACE 2.1 Long Reframe
- `fal-ai/creatify/lipsync` - Creatify Lipsync (realistic, fast)
- `fal-ai/sync-lipsync/v2` - Sync Lipsync 2.0
- `fal-ai/pixverse/lipsync` - PixVerse Lipsync
- `fal-ai/mirelo-ai/sfx-v1/video-to-video` - Mirelo SFX v1 (video + sound)
- `fal-ai/bria/video/background-removal` - Bria Video Background Removal

---

## 🎤 Video-to-Audio Models

### 🆕 New Models to Add
- `fal-ai/kling-video/video-to-audio` - Kling Video-to-Audio
- `fal-ai/mirelo-ai/sfx-v1/video-to-audio` - Mirelo SFX v1 (sound only)

---

## 🔊 Text-to-Speech / Audio Models

### 🆕 New Models to Add
- `fal-ai/index-tts-2/text-to-speech` - Index TTS 2.0
- `fal-ai/chatterbox/text-to-speech` - Chatterbox TTS (Resemble AI)
- `fal-ai/playai/tts/dialog` - PlayAI Dialog TTS (multi-speaker)
- `fal-ai/minimax/speech-02-hd` - MiniMax Speech-02 HD
- `fal-ai/dia-tts/voice-clone` - Dia TTS Voice Clone

---

## 🎨 Image-to-Image / Image Editing

### 🆕 New Models to Add
- `fal-ai/dreamomni2/edit` - DreamOmni2 (text & image guided editing)
- `fal-ai/flux-pro/kontext` - Flux Kontext Pro (local edits, scene transforms)
- `fal-ai/flux-kontext-lora` - Flux Kontext LoRA
- `fal-ai/flux-kontext-lora/inpaint` - Flux Kontext LoRA Inpaint
- `fal-ai/flux-pro/kontext/max` - Flux Pro Kontext Max
- `fal-ai/flux-pro/kontext/max/multi` - Flux Pro Kontext Max Multi
- `fal-ai/flux-pro/kontext/multi` - Flux Pro Kontext Multi
- `fal-ai/topaz/upscale/image` - Topaz Image Upscaler
- `fal-ai/bria/background/remove` - Bria Background Removal

---

## 🎥 Avatar / Lipsync Models

### ✅ Already Configured
- `fal-ai/kling-video/v1/pro/ai-avatar` - Kling AI Avatar Pro

### 🆕 New Models to Add
- `fal-ai/creatify/lipsync` - Creatify Lipsync (speed + quality)
- `fal-ai/bytedance/omnihuman` - OmniHuman (human + audio)
- `fal-ai/ai-avatar/single-text` - MultiTalk (image + text)
- `fal-ai/sync-lipsync/v2` - Sync Lipsync 2.0
- `fal-ai/pixverse/lipsync` - PixVerse Lipsync

---

## 👁️ Vision / Detection Models

### 🆕 New Models to Add
- `fal-ai/moondream3-preview/detect` - Moondream 3 Detection
- `fal-ai/moondream3-preview/point` - Moondream 3 Pointing
- `fal-ai/moondream3-preview/query` - Moondream 3 Query
- `fal-ai/moondream3-preview/caption` - Moondream 3 Caption
- `fal-ai/x-ailab/nsfw` - NSFW Detection (safety filter)

---

## 🎓 Training / LoRA Models

### 🆕 New Models to Add
- `fal-ai/flux-lora-portrait-trainer` - Flux LoRA Portrait Trainer
- `fal-ai/flux-kontext-trainer` - Flux Kontext LoRA Trainer
- `fal-ai/flux-lora-fast-training` - Flux LoRA Fast Training
- `fal-ai/wan-trainer/t2v-14b` - Wan 2.1 T2V 14B Trainer
- `fal-ai/flux-pro-trainer` - Flux Pro Trainer
- `fal-ai/wan-22-image-trainer` - Wan 2.2 Image Trainer

---

## 🧊 3D Models

### 🆕 New Models to Add
- `fal-ai/hunyuan-part` - Hunyuan Part (3D to point cloud)
- `fal-ai/meshy/v6-preview/text-to-3d` - Meshy v6 Text-to-3D
- `fal-ai/meshy/v5/multi-image-to-3d` - Meshy v5 Multi-Image-to-3D
- `fal-ai/meshy/v6-preview/image-to-3d` - Meshy v6 Image-to-3D

---

## 🛠️ Utility Models

### 🆕 New Models to Add
- `fal-ai/topaz/upscale/video` - Topaz Video Upscaler
- `fal-ai/bria/video/background-removal` - Bria Video BG Removal
- `fal-ai/bria/background/remove` - Bria Image BG Removal
- `fal-ai/x-ailab/nsfw` - NSFW Filter

---

## 📊 Summary

### Current Status
- **Total Models Listed**: ~100+
- **Already Configured**: 17 models
- **New Models to Add**: 80+ models
- **Categories**: 12 categories

### Priority Implementation Order
1. **High Priority**: Text-to-Video, Image-to-Video (most requested)
2. **Medium Priority**: Audio/TTS, Avatar/Lipsync
3. **Low Priority**: 3D, Training, Utility models

### Next Steps
1. Implement color-coded category tabs in dropdown
2. Add new models systematically by category
3. Configure API endpoints for each model
4. Test each model integration
5. Update documentation

---

## Color Coding Scheme (for UI)
- 🟦 **Text-to-Image**: Blue
- 🟪 **Text-to-Video**: Purple
- 🟩 **Image-to-Video**: Green
- 🟨 **Video-to-Video**: Yellow
- 🟧 **Video-to-Audio**: Orange
- 🟥 **Audio/TTS**: Red
- 🟫 **Avatar/Lipsync**: Brown
- ⬜ **Vision**: Light Gray
- ⬛ **3D Models**: Dark Gray
- 🟦 **Training**: Cyan
- 🟪 **Image Edit**: Magenta
- 🟩 **Utility**: Teal

---

## 📋 Implementation History

### Session 1 - Initial Setup (2025-01-14)
- ✅ Created model catalog structure
- ✅ Built color-coded ModelSelector component
- ✅ Documented all 100+ models by category
- **Models Configured**: 17
  - Text-to-Image: 3 models (Nano Banana Edit, Seedream 4.0 Edit, Flux Pro)
  - Image-to-Video: 11 models (Sora 2, Veo 3, Kling, Minimax, etc.)
  - Avatar: 1 model (Kling AI Avatar Pro)
  - Video-to-Video: 1 model (EndFrame Minimax)
  - Special: 1 model (Wan Pro - disabled)

### Next Implementation Session
**Target**: Add Text-to-Video category (8-10 models)
- [ ] Kandinsky 5.0 models
- [ ] Veo 3 T2V
- [ ] Ovi
- [ ] Luma Dream Machine
- [ ] Hunyuan Video
- [ ] Kling 2.5 Turbo Pro T2V
- [ ] Sora 2 T2V variants

---

## 🎯 Quick Reference by Status

### Current Dropdown Models (17)
1. fal-ai/nano-banana/edit
2. fal-ai/bytedance/seedream/v4/edit
3. fal-ai/flux-pro/v1.1-ultra
4. fal-ai/sora-2/image-to-video
5. fal-ai/sora-2/image-to-video/pro
6. fal-ai/veo3/image-to-video
7. fal-ai/kling-video/v2.1/master/image-to-video
8. fal-ai/kling-video/v2.5-turbo/pro/image-to-video
9. fal-ai/minimax/hailuo-02/standard/image-to-video
10. fal-ai/hunyuan-video
11. fal-ai/wan-pro/image-to-video (disabled)
12. fal-ai/wan/v2.2-a14b/image-to-video
13. fal-ai/ovi/image-to-video
14. fal-ai/luma-dream-machine/ray-2/image-to-video
15. fal-ai/wan-25-preview/image-to-video
16. fal-ai/kling-video/v1/pro/ai-avatar
17. endframe/minimax-hailuo-02

### High Priority Next Adds
1. Text-to-Video models (high demand)
2. Audio/TTS models (complementary to video)
3. Image editing models (Flux Kontext, DreamOmni2)
4. Avatar/Lipsync models (user engagement)

